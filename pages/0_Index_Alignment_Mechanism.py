"""
üîí M√©canisme de Garantie d'Alignement des Indices

Cette page d√©taille le m√©canisme d'alignement des indices du projet Rakuten,
qui garantit que les pr√©dictions des mod√®les multi-modaux (Image + Texte) peuvent √™tre parfaitement fusionn√©es.
"""

import streamlit as st
from pathlib import Path

# Page configuration
st.set_page_config(
    page_title="M√©canisme d'Alignement des Indices",
    page_icon="üîí",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    .section-header {
        font-size: 1.8rem;
        font-weight: bold;
        color: #1f77b4;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 2px solid #1f77b4;
        padding-bottom: 0.5rem;
    }
    .subsection-header {
        font-size: 1.4rem;
        font-weight: bold;
        color: #ff7f0e;
        margin-top: 1.5rem;
        margin-bottom: 0.8rem;
    }
    .code-section {
        background-color: #f8f9fa;
        border-left: 4px solid #1f77b4;
        padding: 1rem;
        margin: 1rem 0;
    }
    .key-point {
        background-color: #e8f4f8;
        border-left: 4px solid #2ca02c;
        padding: 0.8rem;
        margin: 0.5rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 0.8rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Title
st.markdown("# üîí M√©canisme de Garantie d'Alignement des Indices")
st.markdown("### Principe fondamental : Cha√Æne compl√®te de tra√ßabilit√© des indices depuis les donn√©es brutes jusqu'√† l'export")

st.info("""
**Explication d√©taill√©e de la garantie de coh√©rence des indices.**

Ce m√©canisme garantit que les pr√©dictions des mod√®les Image et Texte peuvent √™tre align√©es pr√©cis√©ment par √©chantillon,
permettant ainsi une fusion s√©curis√©e des mod√®les (Ensemble).
""")

# ========== Premi√®re Garantie : Split Manager Unifi√© ==========
st.markdown('<div class="section-header">üìê Premi√®re Garantie : Split Manager Unifi√©</div>', unsafe_allow_html=True)

st.markdown('<div class="subsection-header">1.1 Source Unique de V√©rit√© (Single Source of Truth)</div>', unsafe_allow_html=True)

st.markdown("""
Tous les mod√®les (Image et Texte) utilisent **exactement les m√™mes** indices de d√©coupage des donn√©es,
qui sont sauvegard√©s dans des fichiers unifi√©s.
""")

with st.expander("üìÑ Voir le code source : src/data/split_manager.py (lignes 23-82)"):
    st.code('''def load_splits(verbose: bool = False) -> Dict[str, np.ndarray]:
    """
    Charge les splits canoniques (indices train/val/test)

    Priorit√© :
    1. Si data/splits/*.txt existe ‚Üí charge directement (source unique de v√©rit√©)
    2. Sinon ‚Üí appelle generate_splits() et sauvegarde dans des fichiers
    """
    train_file = SPLITS_DIR / "train_idx.txt"
    val_file = SPLITS_DIR / "val_idx.txt"
    test_file = SPLITS_DIR / "test_idx.txt"

    # Chargement depuis les fichiers
    if train_file.exists() and val_file.exists() and test_file.exists():
        train_idx = np.loadtxt(train_file, dtype=int)  # Indices de position des donn√©es brutes
        val_idx = np.loadtxt(val_file, dtype=int)
        test_idx = np.loadtxt(test_file, dtype=int)

    return {
        "train_idx": train_idx,  # Exemple : [0, 3, 7, 11, ...]
        "val_idx": val_idx,      # Exemple : [1, 5, 9, 13, ...]
        "test_idx": test_idx     # Exemple : [2, 6, 10, 14, ...]
    }''', language='python')

st.markdown('<div class="key-point">‚úÖ Points cl√©s :</div>', unsafe_allow_html=True)
st.markdown("""
- Retourne les **num√©ros de ligne des donn√©es brutes** (indices de position)
- Tous les mod√®les chargent **exactement les m√™mes** fichiers txt
- Les valeurs d'indices sont **absolues**, par exemple `val_idx[0] = 1` signifie la ligne 1 des donn√©es brutes
""")

st.markdown('<div class="subsection-header">1.2 V√©rification de la Signature du Split</div>', unsafe_allow_html=True)

st.markdown("Utilise un hash SHA256 pour garantir que tous les mod√®les utilisent exactement le m√™me d√©coupage de donn√©es.")

with st.expander("üìÑ Voir le code source : src/data/split_manager.py (lignes 127-152)"):
    st.code('''def split_signature(splits: Dict[str, np.ndarray]) -> str:
    """Calcule la signature SHA256 des splits"""
    train_idx = np.sort(splits["train_idx"])
    val_idx = np.sort(splits["val_idx"])
    test_idx = np.sort(splits["test_idx"])

    combined = np.concatenate([train_idx, val_idx, test_idx])
    content = combined.tobytes()

    hash_obj = hashlib.sha256(content)
    signature = hash_obj.hexdigest()[:16]  # "cf53f8eb169b3531"

    return signature''', language='python')

st.markdown('<div class="key-point">‚úÖ M√©canisme de garantie :</div>', unsafe_allow_html=True)
st.markdown("""
- Tous les mod√®les doivent produire la **m√™me signature**
- La signature est stock√©e dans les fichiers d'export et v√©rifi√©e lors de la fusion
- Signature actuelle du projet : `cf53f8eb169b3531`
""")

# ========== Deuxi√®me Garantie : Cha√Æne de Tra√ßabilit√© des Indices ==========
st.markdown('<div class="section-header">üîó Deuxi√®me Garantie : Cha√Æne de Tra√ßabilit√© des Indices (Flux de Donn√©es Complet)</div>', unsafe_allow_html=True)

st.markdown('<div class="subsection-header">2.1 Flux des Indices pour les Mod√®les Image</div>', unsafe_allow_html=True)

st.markdown("Processus complet de tra√ßabilit√© des indices depuis le chargement des donn√©es jusqu'√† l'export des pr√©dictions :")

# √âtape 1 : Chargement des donn√©es brutes
with st.expander("√âtape 1Ô∏è‚É£ : Chargement des donn√©es brutes (src/data/data_colab.py)"):
    st.code('''# === √âtape 1 : Chargement des donn√©es brutes ===
pack = load_data_colab(raw_dir=..., splitted=False)
X = pack["X"]  # DataFrame, shape: (84916, n_cols)
y = pack["y"]  # Labels bruts

# √âtat des donn√©es brutes :
# Index:  0      1      2      3      4      5    ...  84915
# Image:  img0   img1   img2   img3   img4   img5 ...  img84915
# Label:  10     40     10     50     40     60   ...  ...''', language='python')
    st.markdown("**Source** : `src/data/data_colab.py` (lignes 22-76)")

# √âtape 2 : Chargement des splits unifi√©s
with st.expander("√âtape 2Ô∏è‚É£ : Chargement des splits unifi√©s (src/data/split_manager.py)"):
    st.code('''# === √âtape 2 : Chargement des splits unifi√©s ===
splits = load_splits(verbose=True)

# splits["train_idx"] = [0, 3, 4, 7, 8, ...]  # Num√©ros de ligne des donn√©es brutes
# splits["val_idx"]   = [1, 5, 9, 13, ...]
# splits["test_idx"]  = [2, 6, 10, 14, ...]''', language='python')
    st.markdown("**Source** : `src/data/split_manager.py` (lignes 23-82)")
    st.markdown("**Point cl√©** : Ces indices sont les **num√©ros de ligne absolus** du DataFrame de donn√©es brutes")

# √âtape 3 : Encodage des labels
with st.expander("√âtape 3Ô∏è‚É£ : Encodage des labels (ordre pr√©serv√©) (src/train/image_convnext.py)"):
    st.code('''# === √âtape 3 : Encodage des labels (ordre pr√©serv√©) ===
y_encoded = encode_labels(y, CANONICAL_CLASSES).astype(int)
df_full = X.copy()
df_full["encoded_label"] = y_encoded

# √âtat de df_full (ordre inchang√©) :
# Index:  0      1      2      3      4      5    ...  84915
# Image:  img0   img1   img2   img3   img4   img5 ...  img84915
# Label:  5      15     5      20     15     25   ...  ...  (apr√®s encodage)''', language='python')
    st.markdown("**Source** : `src/train/image_convnext.py` (lignes 503-508)")
    st.markdown('<div class="key-point">‚úÖ Point cl√© : L\'encodage des labels ne modifie pas l\'ordre des lignes du DataFrame</div>', unsafe_allow_html=True)

# √âtape 4 : Cr√©ation du Dataset complet
with st.expander("√âtape 4Ô∏è‚É£ : Cr√©ation du Dataset complet (non d√©coup√©) (src/train/image_convnext.py)"):
    st.code('''# === √âtape 4 : Cr√©ation du Dataset complet (non d√©coup√©) ===
full_dataset = RakutenImageDataset(
    dataframe=df_full.reset_index(drop=True),  # R√©initialise seulement l'index interne, pas l'ordre
    image_dir=img_dir,
    transform=transforms,
    label_col="encoded_label",
)

# full_dataset[i] correspond √† df_full.iloc[i] correspond √† la ligne i des donn√©es brutes''', language='python')
    st.markdown("**Source** : `src/train/image_convnext.py` (lignes 245-258)")
    st.markdown("**Note** : `RakutenImageDataset` est d√©fini dans `src/data/image_dataset.py`")

# √âtape 5 : Enveloppe IndexedDataset
with st.expander("√âtape 5Ô∏è‚É£ : Enveloppe avec IndexedDataset (src/train/image_convnext.py)"):
    st.code('''# === √âtape 5 : Enveloppe avec IndexedDataset ===
train_subset = IndexedDataset(full_dataset, indices=splits["train_idx"])
val_subset = IndexedDataset(full_dataset, indices=splits["val_idx"])

# Principe de fonctionnement d'IndexedDataset :
class IndexedDataset(Dataset):
    """Enveloppe de dataset qui pr√©serve les indices d'origine"""
    def __init__(self, base_dataset: Dataset, indices: np.ndarray):
        self.base = base_dataset
        self.indices = np.asarray(indices).astype(int)

    def __getitem__(self, i: int):
        real_idx = int(self.indices[i])
        img, label = self.base[real_idx]
        return img, label, real_idx  # ‚Üê Retourne l'index d'origine !

# train_subset[0] acc√®de r√©ellement √† full_dataset[splits["train_idx"][0]]
# Retourne (image, label, index d'origine)''', language='python')
    st.markdown("**Source** : `src/train/image_convnext.py` (lignes 104-120, 263-265)")
    st.markdown('<div class="key-point">‚úÖ M√©canisme central : IndexedDataset trace et retourne toujours le num√©ro de ligne des donn√©es brutes</div>', unsafe_allow_html=True)

# √âtape 6 : Export des pr√©dictions
with st.expander("√âtape 6Ô∏è‚É£ : Export des pr√©dictions (src/train/image_convnext.py)"):
    st.code('''# === √âtape 6 : Export des pr√©dictions ===
export_idx = splits["val_idx"]  # [1, 5, 9, 13, ...]

# Pr√©diction sur val_subset, ordre des probs retourn√©s :
probs, seen_idx = _predict_probs_with_real_idx(
    model=model,
    base_dataset=full_dataset,
    indices=export_idx,  # [1, 5, 9, 13, ...]
    ...
)

# probs[0] correspond √† la pr√©diction pour la ligne 1 des donn√©es brutes
# probs[1] correspond √† la pr√©diction pour la ligne 5 des donn√©es brutes
# probs[2] correspond √† la pr√©diction pour la ligne 9 des donn√©es brutes
# seen_idx = [1, 5, 9, 13, ...]  (identique √† export_idx)''', language='python')
    st.markdown("**Source** : `src/train/image_convnext.py` (lignes 426-462, 688-695)")

# √âtape 7 : Sauvegarde en .npz
with st.expander("√âtape 7Ô∏è‚É£ : Sauvegarde en .npz (src/export/model_exporter.py)"):
    st.code('''# === √âtape 7 : Sauvegarde en .npz ===
export_predictions(
    idx=seen_idx,                    # [1, 5, 9, 13, ...]
    probs=probs,                     # shape (n_val, 27)
    y_true=y_encoded[seen_idx],      # Labels aux positions correspondantes des donn√©es brutes
    split_signature=sig,             # "cf53f8eb169b3531"
    ...
)

# Contenu du fichier .npz :
# idx:    [1, 5, 9, 13, ...]        ‚Üê Num√©ros de ligne des donn√©es brutes
# probs:  [[0.1, 0.2, ...],         ‚Üê Probabilit√©s de pr√©diction pour la ligne 1
#          [0.3, 0.1, ...],         ‚Üê Probabilit√©s de pr√©diction pour la ligne 5
#          [0.2, 0.4, ...],         ‚Üê Probabilit√©s de pr√©diction pour la ligne 9
#          ...]
# y_true: [15, 25, 20, ...]         ‚Üê Labels r√©els correspondants''', language='python')
    st.markdown("**Source** : `src/export/model_exporter.py` (lignes 22-150)")
    st.markdown("**Et aussi** : `src/train/image_convnext.py` (lignes 707-738)")

st.markdown('<div class="subsection-header">2.2 Flux des Indices pour les Mod√®les Texte (M√©canisme Identique)</div>', unsafe_allow_html=True)

st.markdown("Les mod√®les Texte suivent exactement le m√™me m√©canisme de tra√ßabilit√© des indices :")

# Mod√®les Texte √âtapes 1-3
with st.expander("√âtapes 1Ô∏è‚É£-3Ô∏è‚É£ : Chargement et pr√©traitement des donn√©es (src/train/text_camembert.py)"):
    st.code('''# === √âtape 1 : Chargement des donn√©es brutes ===
pack = load_data_colab(raw_dir=..., splitted=False)
X = pack["X"]  # DataFrame, shape: (84916, n_cols)
y = pack["y"]

# === √âtape 2 : Chargement des m√™mes splits ===
splits = load_splits(verbose=True)
# Retourne exactement les m√™mes tableaux d'indices (coh√©rents avec les mod√®les Image)

# === √âtape 3 : Construction de la colonne texte (point cl√© : pas de suppression de lignes) ===
X["text"] = build_text_column(X, "designation", "description")

# Traitement des textes vides : remplissage au lieu de suppression
valid_mask = X["text"].str.len() > 0
if not valid_mask.all():
    X.loc[~valid_mask, "text"] = "[EMPTY]"  # ‚úÖ Pr√©serve toutes les lignes

# √âtat de X (nombre de lignes inchang√©) :
# Index: 0      1      2         3      4    ...  84915
# Text:  "..."  "..."  "[EMPTY]" "..."  "..." ...  ...''', language='python')
    st.markdown("**Source** : `src/train/text_camembert.py` (lignes 186-230)")
    st.markdown('<div class="key-point">‚úÖ Principe cl√© : Traiter les textes vides par remplissage plut√¥t que suppression, pr√©server la longueur du DataFrame</div>', unsafe_allow_html=True)

# Mod√®les Texte √âtapes 4-5
with st.expander("√âtapes 4Ô∏è‚É£-5Ô∏è‚É£ : Encodage des labels et d√©coupage des donn√©es (src/train/text_camembert.py)"):
    st.code('''# === √âtape 4 : Encodage des labels (ordre pr√©serv√©) ===
y_encoded = encode_labels(y, CANONICAL_CLASSES).astype(int)
X["label"] = y_encoded

# √âtat de X (ordre compl√®tement inchang√©) :
# Index: 0      1      2         3      4    ...  84915
# Text:  "..."  "..."  "[EMPTY]" "..."  "..." ...  ...
# Label: 5      15     5         20     15   ...  ...

# === √âtape 5 : D√©coupage avec les indices d'origine ===
train_df = X.iloc[splits["train_idx"]].copy().reset_index(drop=True)
val_df = X.iloc[splits["val_idx"]].copy().reset_index(drop=True)

# Note : reset_index(drop=True) n'agit que sur le sous-ensemble apr√®s d√©coupage
# Cela n'affecte pas notre tra√ßabilit√© des indices d'origine

# Index interne de train_df : 0, 1, 2, 3, ...  (continu)
# Mais nous conservons splits["train_idx"] qui conna√Æt les positions d'origine''', language='python')
    st.markdown("**Source** : `src/train/text_camembert.py` (lignes 234-247)")

# Mod√®les Texte √âtapes 6-8
with st.expander("√âtapes 6Ô∏è‚É£-8Ô∏è‚É£ : Entra√Ænement et export (src/train/text_camembert.py)"):
    st.code('''# === √âtape 6 : Cr√©ation du Dataset HF ===
train_ds = Dataset.from_dict({
    "text": train_df["text"].tolist(),
    "label": train_df["label"].tolist(),
})

# train_ds[0] correspond √† train_df.iloc[0]
# correspond √† X.iloc[splits["train_idx"][0]]
# correspond √† la ligne splits["train_idx"][0] des donn√©es brutes

# === √âtape 7 : Pr√©diction apr√®s entra√Ænement ===
export_idx = splits["val_idx"]  # [1, 5, 9, 13, ...]
export_ds = val_ds

predictions = trainer.predict(export_ds)
probs = torch.softmax(torch.tensor(predictions.predictions), dim=-1).numpy()

# Ordre des probs :
# probs[0] correspond √† val_ds[0]
#          correspond √† val_df.iloc[0]
#          correspond √† X.iloc[splits["val_idx"][0]]
#          correspond √† la ligne 1 des donn√©es brutes

# === √âtape 8 : Export (sauvegarde des indices d'origine) ===
y_true = y_encoded[export_idx].astype(int)  # Utilise les indices d'origine pour obtenir les labels

export_predictions(
    idx=export_idx,         # [1, 5, 9, 13, ...] ‚Üê Indices d'origine
    probs=probs,            # shape (n_val, 27)
    y_true=y_true,
    split_signature=sig,
    ...
)''', language='python')
    st.markdown("**Source** : `src/train/text_camembert.py` (lignes 252-400 environ)")

# ========== Troisi√®me Garantie : M√©canisme de V√©rification des Indices ==========
st.markdown('<div class="section-header">üéØ Troisi√®me Garantie : M√©canisme de V√©rification des Indices</div>', unsafe_allow_html=True)

st.markdown('<div class="subsection-header">3.1 V√©rification de Longueur</div>', unsafe_allow_html=True)
st.code('''# image_convnext.py
if len(probs) != len(export_idx):
    raise AssertionError(
        f"Longueur probs ({len(probs)}) "
        f"!= longueur export_idx "
        f"({len(export_idx)})"
    )''', language='python')
st.caption("Source : src/train/image_convnext.py")

st.markdown('<div class="subsection-header">3.2 V√©rification d\'Ordre</div>', unsafe_allow_html=True)
st.code('''# image_convnext.py:698-699
if not np.array_equal(seen_idx, export_idx):
    raise AssertionError(
        "D√©salignement d'ordre d'index "
        "lors de l'inf√©rence d'export"
    )''', language='python')
st.caption("Source : src/train/image_convnext.py (ligne 698)")

st.markdown('<div class="subsection-header">3.3 V√©rification de Signature</div>', unsafe_allow_html=True)
st.code('''# Sauvegarde de la signature lors de l'export
export_predictions(
    split_signature=sig,
    # "cf53f8eb169b3531"
    ...
)

# V√©rification de la signature lors du chargement
loaded = load_predictions(
    npz_path=...,
    verify_split_signature=sig,
    ...
)''', language='python')
st.caption("Source : src/export/model_exporter.py")

# ========== Quatri√®me Garantie : Alignement lors de la Fusion ==========
st.markdown('<div class="section-header">üîÑ Quatri√®me Garantie : Alignement lors de la Fusion</div>', unsafe_allow_html=True)

st.markdown('<div class="subsection-header">4.1 Format des Fichiers d\'Export</div>', unsafe_allow_html=True)

st.markdown("**Structure du fichier NPZ**")
st.code('''{
    "idx": np.array([1, 5, 9, 13, ...]),     # Num√©ros de ligne des donn√©es brutes
    "probs": np.array([[...], [...], ...]),  # Matrice de probabilit√©s
    "y_true": np.array([15, 25, 20, ...]),   # Labels r√©els
}''', language='python')

st.markdown("**M√©tadonn√©es JSON**")
st.code('''{
    "model_name": "convnext_canonical",
    "split_name": "val",
    "split_signature": "cf53f8eb169b3531",
    "classes_fp": "cdfa70b13f7390e6",
    "num_samples": 10827,
    ...
}''', language='json')

st.markdown('<div class="subsection-header">4.2 Processus d\'Alignement pour la Fusion</div>', unsafe_allow_html=True)

with st.expander("üìÑ Voir l'exemple de code d'alignement pour la fusion"):
    st.code('''# === Chargement des pr√©dictions des mod√®les Image ===
img1 = load_predictions("convnext_canonical/val.npz", verify_split_signature=sig)
img2 = load_predictions("swin_canonical/val.npz", verify_split_signature=sig)

# img1["idx"] = [1, 5, 9, 13, ...] ‚Üê Indices d'origine
# img2["idx"] = [1, 5, 9, 13, ...] ‚Üê Exactement identiques

# === Chargement des pr√©dictions des mod√®les Texte ===
text1 = load_predictions("camembert_canonical/val.npz", verify_split_signature=sig)
text2 = load_predictions("xlmr_canonical/val.npz", verify_split_signature=sig)

# text1["idx"] = [1, 5, 9, 13, ...] ‚Üê Exactement identiques
# text2["idx"] = [1, 5, 9, 13, ...] ‚Üê Exactement identiques

# === V√©rification de l'alignement ===
assert np.array_equal(img1["idx"], img2["idx"])
assert np.array_equal(img1["idx"], text1["idx"])
assert np.array_equal(img1["idx"], text2["idx"])

# ‚úÖ Les idx de tous les mod√®les sont compl√®tement identiques

# === Fusion des probabilit√©s (correspondance par ligne) ===
# Puisque les idx sont compl√®tement identiques, on peut fusionner directement par ligne
blended_probs = (
    0.3 * img1["probs"] +      # Ligne i = pr√©diction pour la ligne idx[i] des donn√©es brutes
    0.3 * img2["probs"] +      # Ligne i = pr√©diction pour la ligne idx[i] des donn√©es brutes
    0.2 * text1["probs"] +     # Ligne i = pr√©diction pour la ligne idx[i] des donn√©es brutes
    0.2 * text2["probs"]       # Ligne i = pr√©diction pour la ligne idx[i] des donn√©es brutes
)

# blended_probs[0] = pr√©diction fusionn√©e pour la ligne 1 des donn√©es brutes
# blended_probs[1] = pr√©diction fusionn√©e pour la ligne 5 des donn√©es brutes''', language='python')

# ========== Principes Fondamentaux de Garantie ==========
st.markdown('<div class="section-header">üéì Principes Fondamentaux de Garantie</div>', unsafe_allow_html=True)

principles = [
    {
        "title": "1. Invariance des Indices d'Origine",
        "content": [
            "Apr√®s le chargement des donn√©es brutes, chaque ligne a un indice de position fixe (0 √† 84915)",
            "Toutes les op√©rations sont bas√©es sur cet indice d'origine"
        ]
    },
    {
        "title": "2. Caract√®re Absolu du Split",
        "content": [
            "splits['val_idx'] = [1, 5, 9, ...] sont les num√©ros de ligne absolus des donn√©es brutes",
            "Pas des indices relatifs √† un sous-ensemble"
        ]
    },
    {
        "title": "3. Transmission Explicite des Indices",
        "content": [
            "√Ä chaque √©tape (d√©coupage, entra√Ænement, pr√©diction, export), les indices d'origine sont trac√©s explicitement",
            "Sauvegarde du tableau idx lors de l'export"
        ]
    },
    {
        "title": "4. Principe de Non-Suppression des Donn√©es",
        "content": [
            "Traiter les valeurs manquantes par remplissage plut√¥t que par suppression",
            "Pr√©server la longueur du DataFrame"
        ]
    },
    {
        "title": "5. V√©rification par Signature",
        "content": [
            "Utiliser la signature SHA256 pour garantir que tous les mod√®les utilisent exactement les m√™mes splits",
            "V√©rification obligatoire de la coh√©rence des signatures lors de la fusion"
        ]
    }
]

for i, principle in enumerate(principles):
    with st.container():
        st.markdown(f'<div class="key-point"><b>{principle["title"]}</b></div>', unsafe_allow_html=True)
        for content in principle["content"]:
            st.markdown(f"- {content}")

# ========== R√©sum√© ==========
st.markdown('<div class="section-header">üìä Tableau Comparatif R√©capitulatif</div>', unsafe_allow_html=True)

comparison_data = {
    "Op√©ration": [
        "Pr√©traitement des donn√©es",
        "G√©n√©ration du Split",
        "Tra√ßabilit√© des indices",
        "Format d'export",
        "V√©rification par signature",
        "Alignement pour fusion"
    ],
    "Code Sans Risque (Image & Text 09-12)": [
        "‚úÖ Remplissage des valeurs vides, pr√©servation de toutes les lignes",
        "‚úÖ load_splits() unifi√©",
        "‚úÖ Pr√©servation constante des num√©ros de ligne d'origine",
        "‚úÖ .npz + idx + probs + y_true",
        "‚úÖ V√©rification par signature SHA256",
        "‚úÖ idx compl√®tement identiques, fusion directe"
    ]
}

import pandas as pd
comparison_df = pd.DataFrame(comparison_data)
st.dataframe(comparison_df, use_container_width=True, hide_index=True)

# ========== Explication Finale ==========
st.success("""
**Gr√¢ce √† ce m√©canisme de garantie complet**, m√™me apr√®s un processus d'entra√Ænement complexe,
les r√©sultats de pr√©diction export√©s peuvent toujours correspondre avec pr√©cision √† chaque ligne
des donn√©es d'origine via les idx, r√©alisant un **alignement parfait** et une **fusion s√©curis√©e**
des pr√©dictions des mod√®les Image et Texte.

C'est la cl√© du succ√®s de notre Ensemble multi-modal !
""")

# Footer
st.markdown("---")
st.caption("üìù Cette documentation est g√©n√©r√©e automatiquement √† partir du code source du projet | Rakuten Product Classification Project")
