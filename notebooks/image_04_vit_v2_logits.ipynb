{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT Canonical Training + Phase 3 Export (Colab)\n",
    "\n",
    "**Model:** Vision Transformer (ViT-Tiny via timm)\n",
    "\n",
    "**Objective:** Replicate ResNet50 canonical pipeline with ViT:\n",
    "- Phase 1: Canonical splits (load from Drive)\n",
    "- Phase 2: Canonical classes (27 classes, fp=cdfa70b13f7390e6)\n",
    "- Phase 3: Export contract (.npz + _meta.json) with strict validation\n",
    "\n",
    "**Expected outputs:**\n",
    "- `STORE/artifacts/exports/vit_rerun_canonical_smoke/val.npz`\n",
    "- `STORE/artifacts/exports/vit_rerun_canonical_smoke/val_meta.json`\n",
    "\n",
    "**Validation:**\n",
    "- split_signature must match ResNet50: `cf53f8eb169b3531`\n",
    "- classes_fp must equal canonical: `cdfa70b13f7390e6`\n",
    "- idx order must align with ResNet50 for fusion compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# --- EDIT THESE PATHS ONCE ---\n",
    "DRIVE_CODE_SNAPSHOT = Path(\"/content/drive/MyDrive/DS_rakuten_colab\")\n",
    "DRIVE_STORE = Path(\"/content/drive/MyDrive/DS_rakuten_store\")\n",
    "DRIVE_SPLITS_SRC = DRIVE_STORE / \"splits\"   # expects train_idx.txt / val_idx.txt / test_idx.txt\n",
    "# ----------------------------\n",
    "\n",
    "assert DRIVE_CODE_SNAPSHOT.exists(), f\"Missing code snapshot: {DRIVE_CODE_SNAPSHOT}\"\n",
    "DRIVE_STORE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"DS_RAKUTEN_STORE\"] = str(DRIVE_STORE)\n",
    "\n",
    "print(\"✓ DRIVE_CODE_SNAPSHOT:\", DRIVE_CODE_SNAPSHOT)\n",
    "print(\"✓ DRIVE_STORE:\", DRIVE_STORE)\n",
    "print(\"✓ DRIVE_SPLITS_SRC:\", DRIVE_SPLITS_SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "RUNTIME_ROOT = Path(\"/content/DS_rakuten\")\n",
    "\n",
    "# Clean and copy for deterministic imports\n",
    "if RUNTIME_ROOT.exists():\n",
    "    shutil.rmtree(RUNTIME_ROOT)\n",
    "\n",
    "shutil.copytree(DRIVE_CODE_SNAPSHOT, RUNTIME_ROOT)\n",
    "\n",
    "sys.path.insert(0, str(RUNTIME_ROOT))\n",
    "\n",
    "print(\"✓ Runtime code ready:\", RUNTIME_ROOT)\n",
    "print(\"✓ sys.path[0]:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "runtime_splits_dir = Path(\"/content/DS_rakuten/data/splits\")\n",
    "runtime_splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy txt files from Drive persistent store into /content runtime repo\n",
    "src_files = [\"train_idx.txt\", \"val_idx.txt\", \"test_idx.txt\"]\n",
    "for fn in src_files:\n",
    "    src = DRIVE_SPLITS_SRC / fn\n",
    "    dst = runtime_splits_dir / fn\n",
    "    assert src.exists(), f\"Missing split file in Drive: {src}\"\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "print(\"✓ Splits synced to:\", runtime_splits_dir)\n",
    "print(\"✓ Contents:\", list(runtime_splits_dir.glob(\"*.txt\"))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install timm for Vision Transformer models\n",
    "!pip -q install timm wandb\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# Uncomment if your session is missing other packages:\n",
    "# !pip -q install gdown\n",
    "# !pip -q install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGE_FILE_ID = \"15ZkS0iTQ7j3mHpxil4mABlXwP-jAN_zi\"\n",
    "\n",
    "BASE_DIR = Path(\"/content/images\")\n",
    "TMP_DIR = Path(\"/content/tmp\")\n",
    "ZIP_PATH = TMP_DIR / \"images.zip\"\n",
    "\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not ZIP_PATH.exists():\n",
    "    print(\"Downloading images zip...\")\n",
    "    !gdown --id $IMAGE_FILE_ID -O {str(ZIP_PATH)}\n",
    "else:\n",
    "    print(\"Zip already present:\", ZIP_PATH)\n",
    "\n",
    "print(\"Unzipping images...\")\n",
    "!unzip -q -o {str(ZIP_PATH)} -d {str(BASE_DIR)}\n",
    "\n",
    "def count_jpgs(p: Path, limit: int = 2000) -> int:\n",
    "    if not p.exists():\n",
    "        return 0\n",
    "    n = 0\n",
    "    for _ in p.rglob(\"*.jpg\"):\n",
    "        n += 1\n",
    "        if n >= limit:\n",
    "            break\n",
    "    return n\n",
    "\n",
    "# Common candidates\n",
    "candidates = [\n",
    "    BASE_DIR / \"images\" / \"image_train\",\n",
    "    BASE_DIR / \"image_train\",\n",
    "    BASE_DIR / \"images\" / \"images\" / \"image_train\",\n",
    "]\n",
    "\n",
    "best = None\n",
    "best_count = 0\n",
    "for c in candidates:\n",
    "    n = count_jpgs(c)\n",
    "    if n > best_count:\n",
    "        best, best_count = c, n\n",
    "\n",
    "# Fallback: search any folder named image_train\n",
    "if best_count == 0:\n",
    "    for c in BASE_DIR.rglob(\"image_train\"):\n",
    "        if c.is_dir():\n",
    "            n = count_jpgs(c)\n",
    "            if n > best_count:\n",
    "                best, best_count = c, n\n",
    "\n",
    "assert best is not None and best_count > 0, (\n",
    "    \"Could not find an image_train directory with jpg files under /content/images. \"\n",
    "    \"Check zip content and unzip path.\"\n",
    ")\n",
    "\n",
    "IMG_ROOT = best\n",
    "sample_jpg = next(IMG_ROOT.rglob(\"*.jpg\"))\n",
    "\n",
    "print(\"✓ IMG_ROOT detected:\", IMG_ROOT)\n",
    "print(\"✓ sample jpg:\", sample_jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.image_dataset import RakutenImageDataset\n",
    "from src.train.image_vit import ViTConfig, run_vit_canonical\n",
    "\n",
    "print(\"✓ RakutenImageDataset:\", RakutenImageDataset)\n",
    "print(\"✓ ViTConfig:\", ViTConfig)\n",
    "print(\"✓ run_vit_canonical:\", run_vit_canonical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.split_manager import load_splits, split_signature\n",
    "\n",
    "splits = load_splits(verbose=True)\n",
    "sig = split_signature(splits)\n",
    "\n",
    "print(\"✓ signature:\", sig)\n",
    "print({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# EXPORT TEST LOGITS (without retraining)\n# Load pretrained ViT checkpoint and export test set logits\n# ============================================================\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport timm\n\nfrom src.data.data_colab import load_data_colab\nfrom src.data.split_manager import load_splits, split_signature\nfrom src.data.label_mapping import (\n    CANONICAL_CLASSES,\n    CANONICAL_CLASSES_FP,\n    encode_labels,\n)\nfrom src.export.model_exporter import export_predictions, load_predictions\nfrom src.data.image_dataset import RakutenImageDataset\n\n# ---- Configuration ----\nSTORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\nCKPT_PATH = STORE / \"checkpoints\" / \"image_vit\" / \"best_model.pth\"\nOUT_DIR = STORE / \"artifacts\" / \"exports\"\nRAW_DIR = str(STORE / \"data_raw\")\n\nIMG_SIZE = 224\nBATCH_SIZE = 32\nNUM_CLASSES = 27\nDROPOUT_RATE = 0.1\nVIT_MODEL_NAME = \"vit_tiny_patch16_224\"  # embed_dim=192, confirmed from checkpoint\nMODEL_NAME = \"vit_canonical\"  # Same directory as val.npz\n\nprint(\"=\" * 60)\nprint(\"EXPORT TEST LOGITS - ViT\")\nprint(\"=\" * 60)\nprint(f\"Checkpoint: {CKPT_PATH}\")\nprint(f\"Output dir: {OUT_DIR / MODEL_NAME}\")\n\n# ---- Verify checkpoint exists ----\nassert CKPT_PATH.exists(), f\"Checkpoint not found: {CKPT_PATH}\"\nprint(f\"✓ Checkpoint found: {CKPT_PATH}\")\n\n# ---- Build model architecture ----\ndef build_vit(num_classes: int, dropout_rate: float, model_name: str) -> nn.Module:\n    model = timm.create_model(\n        model_name,\n        pretrained=False,  # We'll load our own weights\n        num_classes=int(num_classes),\n        drop_rate=float(dropout_rate),\n    )\n    return model\n\n# ---- Load checkpoint ----\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\n\nmodel = build_vit(NUM_CLASSES, DROPOUT_RATE, VIT_MODEL_NAME).to(device)\nckpt = torch.load(CKPT_PATH, map_location=device)\nmodel.load_state_dict(ckpt[\"model_state_dict\"])\nmodel.eval()\n\nprint(f\"✓ Model loaded from epoch {ckpt.get('epoch', '?')}\")\nprint(f\"✓ Best val F1: {ckpt.get('best_val_f1', '?'):.4f}\")\nprint(f\"✓ Split signature: {ckpt.get('split_signature', '?')}\")\n\n# ---- Load data ----\npack = load_data_colab(\n    raw_dir=RAW_DIR,\n    img_root=IMG_ROOT,\n    splitted=False,\n    verbose=True,\n)\nX, y = pack[\"X\"], pack[\"y\"]\n\n# ---- Splits and labels ----\nsplits = load_splits(verbose=True)\nsig = split_signature(splits)\ny_encoded = encode_labels(y, CANONICAL_CLASSES).astype(int)\n\nprint(f\"✓ Split signature: {sig}\")\nprint(f\"✓ Test set size: {len(splits['test_idx'])}\")\n\n# ---- Prepare test dataset ----\nval_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.CenterCrop(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\nfull_df = X.copy()\nfull_df[\"encoded_label\"] = y_encoded\n\n# IndexedDataset to track real indices\nclass IndexedDataset(Dataset):\n    def __init__(self, base_dataset: Dataset, indices: np.ndarray):\n        self.base = base_dataset\n        self.indices = np.asarray(indices).astype(int)\n\n    def __len__(self) -> int:\n        return len(self.indices)\n\n    def __getitem__(self, i: int):\n        real_idx = int(self.indices[i])\n        img, label = self.base[real_idx]\n        return img, label, real_idx\n\nfull_dataset = RakutenImageDataset(\n    dataframe=full_df.reset_index(drop=True),\n    image_dir=str(IMG_ROOT),\n    transform=val_transform,\n    label_col=\"encoded_label\",\n)\n\ntest_idx = splits[\"test_idx\"]\ntest_dataset = IndexedDataset(full_dataset, test_idx)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=0,  # Colab stability\n    pin_memory=device.startswith(\"cuda\"),\n)\n\nprint(f\"✓ Test DataLoader ready: {len(test_loader)} batches\")\n\n# ---- Inference: Extract LOGITS (not softmax probs) ----\n@torch.no_grad()\ndef predict_logits(model, loader, device):\n    model.eval()\n    logits_list = []\n    idx_list = []\n    \n    for images, _, real_idx in tqdm(loader, desc=\"Test Inference\", ncols=100):\n        images = images.to(device, non_blocking=True)\n        logits = model(images)  # Raw logits, NO softmax\n        logits_list.append(logits.detach().cpu().numpy())\n        idx_list.append(real_idx.detach().cpu().numpy())\n    \n    logits = np.concatenate(logits_list, axis=0)\n    idx = np.concatenate(idx_list, axis=0)\n    return logits, idx\n\nprint(\"Running inference on test set...\")\ntest_logits, seen_idx = predict_logits(model, test_loader, device)\n\n# ---- Verify alignment ----\nif not np.array_equal(seen_idx, test_idx):\n    raise AssertionError(\"Index order mismatch during test inference!\")\n\nprint(f\"✓ Inference complete: logits shape = {test_logits.shape}\")\n\n# ---- Get y_true for test set ----\ny_true_test = y_encoded[test_idx].astype(int)\n\n# ---- Export test logits ----\nexport_result = export_predictions(\n    out_dir=OUT_DIR,\n    model_name=MODEL_NAME,\n    split_name=\"test\",\n    idx=seen_idx,\n    split_signature=sig,\n    logits=test_logits,  # Export LOGITS, not probs\n    classes=CANONICAL_CLASSES,\n    y_true=y_true_test,\n    extra_meta={\n        \"source\": \"image_04_vit_v2_logits.ipynb\",\n        \"model_architecture\": f\"timm.{VIT_MODEL_NAME}\",\n        \"img_dir\": str(IMG_ROOT),\n        \"img_size\": IMG_SIZE,\n        \"batch_size\": BATCH_SIZE,\n        \"dropout_rate\": DROPOUT_RATE,\n        \"output_type\": \"logits\",\n        \"checkpoint_path\": str(CKPT_PATH),\n        \"classes_fp\": CANONICAL_CLASSES_FP,\n        \"split_signature\": sig,\n    },\n)\n\nprint()\nprint(\"=\" * 60)\nprint(\"EXPORT COMPLETE\")\nprint(\"=\" * 60)\nprint(f\"NPZ path: {export_result['npz_path']}\")\nprint(f\"Meta JSON: {export_result['meta_json_path']}\")\nprint(f\"Samples: {export_result['num_samples']}\")\nprint(f\"Split signature: {export_result['split_signature']}\")\n\n# ---- Verify export ----\nloaded = load_predictions(\n    npz_path=export_result[\"npz_path\"],\n    verify_split_signature=sig,\n    verify_classes_fp=CANONICAL_CLASSES_FP,\n    require_y_true=True,\n)\n\nprint()\nprint(\"✓ Export verification passed!\")\nprint(f\"  - model: {loaded['metadata']['model_name']}\")\nprint(f\"  - split: {loaded['metadata']['split_name']}\")\nprint(f\"  - output_type: {loaded['metadata'].get('output_type', 'probs')}\")\nprint(f\"  - logits shape: {loaded['logits'].shape}\")\nprint(f\"  - has_y_true: {loaded['metadata']['has_y_true']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# TRAINING CODE (SKIP - already trained)\n# ============================================================\n# The model has already been trained and checkpoint saved.\n# Run cell-8 above to export test logits without retraining.\n# \n# Original training code is commented out below for reference:\n# ------------------------------------------------------------\n# cfg = ViTConfig(\n#     raw_dir=str(STORE / \"data_raw\"),\n#     img_dir=str(IMG_ROOT),  \n#     out_dir=str(STORE / \"artifacts\" / \"exports\"),\n#     ckpt_dir=str(STORE / \"checkpoints\" / \"image_vit\"),\n#     img_size=224,\n#     batch_size=32, \n#     num_workers=8,\n#     num_epochs=5, \n#     lr=1e-4,\n#     use_amp=True,\n#     label_smoothing=0.1,\n#     dropout_rate=0.1,\n#     vit_model_name=\"vit_base_patch16_224\",\n#     vit_pretrained=True,\n#     force_colab_loader=True,\n#     model_name=\"vit_base_canonical_smoke\",\n#     export_split=\"val\",\n#     use_wandb=True,\n#     wandb_project=\"rakuten-vit-colab-smoke\"\n# )\n# result = run_vit_canonical(cfg)\nprint(\"Training code skipped - model already trained.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}