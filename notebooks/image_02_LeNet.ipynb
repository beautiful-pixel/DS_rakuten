{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {
        "id": "cell-0"
      },
      "source": [
        "# LeNet-5 Canonical Training + Phase 3 Export (Colab)\n",
        "\n",
        "**Model:** LeNet-5 (adapted for 32x32 RGB images)\n",
        "\n",
        "**Objective:**\n",
        "- Phase 1: Canonical splits (load from Drive)\n",
        "- Phase 2: Canonical classes (27 classes, fp=cdfa70b13f7390e6)\n",
        "- Phase 3: Export contract (.npz + _meta.json) with strict validation\n",
        "\n",
        "**Expected outputs:**\n",
        "- `STORE/artifacts/exports/lenet_canonical/val.npz`\n",
        "- `STORE/artifacts/exports/lenet_canonical/val_meta.json`\n",
        "\n",
        "**Validation:**\n",
        "- split_signature must match ResNet50: `cf53f8eb169b3531`\n",
        "- classes_fp must equal canonical: `cdfa70b13f7390e6`\n",
        "- idx order must align with ResNet50 for fusion compatibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cell-1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-1",
        "outputId": "7710c588-c553-444e-cc5f-d508f3994e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✓ DRIVE_CODE_SNAPSHOT: /content/drive/MyDrive/DS_rakuten_colab\n",
            "✓ DRIVE_STORE: /content/drive/MyDrive/DS_rakuten_store\n",
            "✓ DRIVE_SPLITS_SRC: /content/drive/MyDrive/DS_rakuten_store/splits\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# --- EDIT THESE PATHS ONCE ---\n",
        "DRIVE_CODE_SNAPSHOT = Path(\"/content/drive/MyDrive/DS_rakuten_colab\")\n",
        "DRIVE_STORE = Path(\"/content/drive/MyDrive/DS_rakuten_store\")\n",
        "DRIVE_SPLITS_SRC = DRIVE_STORE / \"splits\"   # expects train_idx.txt / val_idx.txt / test_idx.txt\n",
        "# ----------------------------\n",
        "\n",
        "assert DRIVE_CODE_SNAPSHOT.exists(), f\"Missing code snapshot: {DRIVE_CODE_SNAPSHOT}\"\n",
        "DRIVE_STORE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "os.environ[\"DS_RAKUTEN_STORE\"] = str(DRIVE_STORE)\n",
        "\n",
        "print(\"✓ DRIVE_CODE_SNAPSHOT:\", DRIVE_CODE_SNAPSHOT)\n",
        "print(\"✓ DRIVE_STORE:\", DRIVE_STORE)\n",
        "print(\"✓ DRIVE_SPLITS_SRC:\", DRIVE_SPLITS_SRC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cell-2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-2",
        "outputId": "c0defcab-6ad3-4876-b592-97314cd282e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Runtime code ready: /content/DS_rakuten\n",
            "✓ sys.path[0]: /content/DS_rakuten\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "RUNTIME_ROOT = Path(\"/content/DS_rakuten\")\n",
        "\n",
        "# Clean and copy for deterministic imports\n",
        "if RUNTIME_ROOT.exists():\n",
        "    shutil.rmtree(RUNTIME_ROOT)\n",
        "\n",
        "shutil.copytree(DRIVE_CODE_SNAPSHOT, RUNTIME_ROOT)\n",
        "\n",
        "sys.path.insert(0, str(RUNTIME_ROOT))\n",
        "\n",
        "print(\"✓ Runtime code ready:\", RUNTIME_ROOT)\n",
        "print(\"✓ sys.path[0]:\", sys.path[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cell-3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-3",
        "outputId": "821c8769-44f2-44e2-a3f8-f7a973f15401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Splits synced to: /content/DS_rakuten/data/splits\n",
            "✓ Contents: [PosixPath('/content/DS_rakuten/data/splits/val_idx.txt'), PosixPath('/content/DS_rakuten/data/splits/test_idx.txt'), PosixPath('/content/DS_rakuten/data/splits/train_idx.txt')]\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "runtime_splits_dir = Path(\"/content/DS_rakuten/data/splits\")\n",
        "runtime_splits_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy txt files from Drive persistent store into /content runtime repo\n",
        "src_files = [\"train_idx.txt\", \"val_idx.txt\", \"test_idx.txt\"]\n",
        "for fn in src_files:\n",
        "    src = DRIVE_SPLITS_SRC / fn\n",
        "    dst = runtime_splits_dir / fn\n",
        "    assert src.exists(), f\"Missing split file in Drive: {src}\"\n",
        "    shutil.copy2(src, dst)\n",
        "\n",
        "print(\"✓ Splits synced to:\", runtime_splits_dir)\n",
        "print(\"✓ Contents:\", list(runtime_splits_dir.glob(\"*.txt\"))[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cell-4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-4",
        "outputId": "915541ca-4257-4f26-c8fd-5ce298c3905a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxiaosong-dev\u001b[0m (\u001b[33mxiaosong-dev-formation-data-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Install wandb for experiment tracking\n",
        "!pip -q install wandb\n",
        "\n",
        "# Uncomment if your session is missing other packages:\n",
        "# !pip -q install gdown\n",
        "# !pip -q install scikit-learn\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cell-5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-5",
        "outputId": "422291b7-95e7-41ac-dea9-059ed5dba270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip already present: /content/tmp/images.zip\n",
            "Unzipping images...\n",
            "✓ IMG_ROOT detected: /content/images/images/image_train\n",
            "✓ sample jpg: /content/images/images/image_train/image_1068762146_product_1199752710.jpg\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGE_FILE_ID = \"15ZkS0iTQ7j3mHpxil4mABlXwP-jAN_zi\"\n",
        "\n",
        "BASE_DIR = Path(\"/content/images\")\n",
        "TMP_DIR = Path(\"/content/tmp\")\n",
        "ZIP_PATH = TMP_DIR / \"images.zip\"\n",
        "\n",
        "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if not ZIP_PATH.exists():\n",
        "    print(\"Downloading images zip...\")\n",
        "    !gdown --id $IMAGE_FILE_ID -O {str(ZIP_PATH)}\n",
        "else:\n",
        "    print(\"Zip already present:\", ZIP_PATH)\n",
        "\n",
        "print(\"Unzipping images...\")\n",
        "!unzip -q -o {str(ZIP_PATH)} -d {str(BASE_DIR)}\n",
        "\n",
        "def count_jpgs(p: Path, limit: int = 2000) -> int:\n",
        "    if not p.exists():\n",
        "        return 0\n",
        "    n = 0\n",
        "    for _ in p.rglob(\"*.jpg\"):\n",
        "        n += 1\n",
        "        if n >= limit:\n",
        "            break\n",
        "    return n\n",
        "\n",
        "# Common candidates\n",
        "candidates = [\n",
        "    BASE_DIR / \"images\" / \"image_train\",\n",
        "    BASE_DIR / \"image_train\",\n",
        "    BASE_DIR / \"images\" / \"images\" / \"image_train\",\n",
        "]\n",
        "\n",
        "best = None\n",
        "best_count = 0\n",
        "for c in candidates:\n",
        "    n = count_jpgs(c)\n",
        "    if n > best_count:\n",
        "        best, best_count = c, n\n",
        "\n",
        "# Fallback: search any folder named image_train\n",
        "if best_count == 0:\n",
        "    for c in BASE_DIR.rglob(\"image_train\"):\n",
        "        if c.is_dir():\n",
        "            n = count_jpgs(c)\n",
        "            if n > best_count:\n",
        "                best, best_count = c, n\n",
        "\n",
        "assert best is not None and best_count > 0, (\n",
        "    \"Could not find an image_train directory with jpg files under /content/images. \"\n",
        "    \"Check zip content and unzip path.\"\n",
        ")\n",
        "\n",
        "IMG_ROOT = best\n",
        "sample_jpg = next(IMG_ROOT.rglob(\"*.jpg\"))\n",
        "\n",
        "print(\"✓ IMG_ROOT detected:\", IMG_ROOT)\n",
        "print(\"✓ sample jpg:\", sample_jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cell-6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-6",
        "outputId": "d9bd675a-0851-45de-b86e-a90916e77b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ RakutenImageDataset: <class 'src.data.image_dataset.RakutenImageDataset'>\n",
            "✓ LeNetConfig: <class 'src.train.image_lenet.LeNetConfig'>\n",
            "✓ run_lenet_canonical: <function run_lenet_canonical at 0x7c90b43e4360>\n"
          ]
        }
      ],
      "source": [
        "from src.data.image_dataset import RakutenImageDataset\n",
        "from src.train.image_lenet import LeNetConfig, run_lenet_canonical\n",
        "\n",
        "print(\"✓ RakutenImageDataset:\", RakutenImageDataset)\n",
        "print(\"✓ LeNetConfig:\", LeNetConfig)\n",
        "print(\"✓ run_lenet_canonical:\", run_lenet_canonical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cell-7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-7",
        "outputId": "6c1dfcb9-ad20-4723-d0c5-dd3b2b1cdb24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[split_manager] Loading canonical splits from /content/DS_rakuten/data/splits\n",
            "✓ signature: cf53f8eb169b3531\n",
            "{'train_idx': 61351, 'val_idx': 10827, 'test_idx': 12738}\n"
          ]
        }
      ],
      "source": [
        "from src.data.split_manager import load_splits, split_signature\n",
        "\n",
        "splits = load_splits(verbose=True)\n",
        "sig = split_signature(splits)\n",
        "\n",
        "print(\"✓ signature:\", sig)\n",
        "print({k: len(v) for k, v in splits.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cell-8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cell-8",
        "outputId": "e9a6001f-6f66-4516-fa84-d625e938d46c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260110_104558-7otxfed6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image/runs/7otxfed6' target=\"_blank\">lenet</a></strong> to <a href='https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image' target=\"_blank\">https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image/runs/7otxfed6' target=\"_blank\">https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image/runs/7otxfed6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using Colab data loader (forced via force_colab_loader=True)\n",
            "[load_data_colab] raw_dir: /content/drive/MyDrive/DS_rakuten_store/data_raw\n",
            "[load_data_colab] img_root: /content/images/images/image_train\n",
            "[load_data_colab] X: /content/drive/MyDrive/DS_rakuten_store/data_raw/X_train_update.csv\n",
            "[load_data_colab] Y: /content/drive/MyDrive/DS_rakuten_store/data_raw/Y_train_CVw08PX.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[split_manager] Loading canonical splits from /content/DS_rakuten/data/splits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 | train_loss=2.9326 train_f1=0.1055 | val_loss=2.6894 val_f1=0.1713 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 | train_loss=2.7103 train_f1=0.1647 | val_loss=2.5358 val_f1=0.1844 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 | train_loss=2.6318 train_f1=0.1848 | val_loss=2.4539 val_f1=0.2171 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 | train_loss=2.5864 train_f1=0.1972 | val_loss=2.4320 val_f1=0.2267 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 | train_loss=2.5505 train_f1=0.2112 | val_loss=2.3794 val_f1=0.2436 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 | train_loss=2.5203 train_f1=0.2184 | val_loss=2.3701 val_f1=0.2463 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 | train_loss=2.5039 train_f1=0.2245 | val_loss=2.3696 val_f1=0.2481 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 | train_loss=2.4888 train_f1=0.2297 | val_loss=2.3338 val_f1=0.2667 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 | train_loss=2.4782 train_f1=0.2306 | val_loss=2.3414 val_f1=0.2679 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 | train_loss=2.4666 train_f1=0.2349 | val_loss=2.3221 val_f1=0.2575 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 | train_loss=2.4506 train_f1=0.2383 | val_loss=2.3213 val_f1=0.2626 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 | train_loss=2.4481 train_f1=0.2403 | val_loss=2.3033 val_f1=0.2730 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 | train_loss=2.4430 train_f1=0.2431 | val_loss=2.2823 val_f1=0.2805 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 | train_loss=2.4398 train_f1=0.2436 | val_loss=2.2899 val_f1=0.2745 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 | train_loss=2.4384 train_f1=0.2458 | val_loss=2.2834 val_f1=0.2820 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 | train_loss=2.4275 train_f1=0.2491 | val_loss=2.2693 val_f1=0.2853 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 | train_loss=2.4238 train_f1=0.2511 | val_loss=2.2621 val_f1=0.2836 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 | train_loss=2.4132 train_f1=0.2522 | val_loss=2.2840 val_f1=0.2844 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 | train_loss=2.4148 train_f1=0.2538 | val_loss=2.2696 val_f1=0.2917 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 | train_loss=2.4158 train_f1=0.2522 | val_loss=2.2746 val_f1=0.2863 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 | train_loss=2.4166 train_f1=0.2537 | val_loss=2.2741 val_f1=0.2821 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 | train_loss=2.4065 train_f1=0.2548 | val_loss=2.2546 val_f1=0.2891 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 | train_loss=2.4052 train_f1=0.2565 | val_loss=2.2568 val_f1=0.2929 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 | train_loss=2.4024 train_f1=0.2605 | val_loss=2.2497 val_f1=0.2930 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 | train_loss=2.3998 train_f1=0.2575 | val_loss=2.2441 val_f1=0.2913 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 | train_loss=2.3974 train_f1=0.2583 | val_loss=2.2438 val_f1=0.2966 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30 | train_loss=2.3942 train_f1=0.2613 | val_loss=2.2380 val_f1=0.2978 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30 | train_loss=2.3909 train_f1=0.2630 | val_loss=2.2381 val_f1=0.2949 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30 | train_loss=2.3891 train_f1=0.2604 | val_loss=2.2326 val_f1=0.2967 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|                                                                | 0/479 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Val:   0%|                                                                   | 0/85 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30 | train_loss=2.3842 train_f1=0.2613 | val_loss=2.2349 val_f1=0.2921 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Exported model=lenet_canonical split=val npz=/content/drive/MyDrive/DS_rakuten_store/artifacts/exports/lenet_canonical/val.npz sig=cf53f8eb169b3531 fp=cdfa70b13f7390e6 n=10827\n",
            "EXPORT: {'npz_path': '/content/drive/MyDrive/DS_rakuten_store/artifacts/exports/lenet_canonical/val.npz', 'meta_json_path': '/content/drive/MyDrive/DS_rakuten_store/artifacts/exports/lenet_canonical/val_meta.json', 'classes_fp': 'cdfa70b13f7390e6', 'split_signature': 'cf53f8eb169b3531', 'num_samples': 10827}\n",
            "VERIFY: {'model_name': 'lenet_canonical', 'split_name': 'val', 'split_signature': 'cf53f8eb169b3531', 'classes_fp': 'cdfa70b13f7390e6', 'num_classes': 27, 'num_samples': 10827, 'has_y_true': True, 'probs_shape': [10827, 27], 'probs_dtype': 'float32', 'created_at': '2026-01-10T14:06:28.408471', 'extra': {'source': 'src/train/image_lenet.py', 'model_architecture': 'LeNet-5', 'img_dir': '/content/images/images/image_train', 'img_size': 32, 'batch_size': 128, 'num_epochs': 30, 'lr': 0.001, 'weight_decay': 0.0001, 'use_amp': False, 'dropout_rate': 0.5, 'classes_fp': 'cdfa70b13f7390e6', 'split_signature': 'cf53f8eb169b3531', 'export_split': 'val'}}\n",
            "probs_shape: (10827, 27)\n",
            "best_val_f1: 0.2978410616056831\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_f1</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>val_f1</td><td>▁▂▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇█▇▇█████████</td></tr><tr><td>val_loss</td><td>█▆▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_f1</td><td>0.29784</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_acc</td><td>0.31243</td></tr><tr><td>train_f1</td><td>0.26132</td></tr><tr><td>train_loss</td><td>2.38424</td></tr><tr><td>val_acc</td><td>0.35042</td></tr><tr><td>val_f1</td><td>0.29209</td></tr><tr><td>val_loss</td><td>2.23493</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lenet</strong> at: <a href='https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image/runs/7otxfed6' target=\"_blank\">https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image/runs/7otxfed6</a><br> View project at: <a href='https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image' target=\"_blank\">https://wandb.ai/xiaosong-dev-formation-data-science/rakuten_image</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260110_104558-7otxfed6/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "STORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\n",
        "\n",
        "wandb.init(\n",
        "    project=\"rakuten_image\",\n",
        "    name=\"lenet\",\n",
        "    config={\n",
        "        \"model\": \"LeNet-5\",\n",
        "        \"batch_size\": 128,\n",
        "        \"lr\": 1e-3,\n",
        "        \"epochs\": 30,\n",
        "    }\n",
        ")\n",
        "\n",
        "cfg = LeNetConfig(\n",
        "    raw_dir=str(STORE / \"data_raw\"),\n",
        "    img_dir=str(IMG_ROOT),  # must be /content local disk for speed\n",
        "    out_dir=str(STORE / \"artifacts\" / \"exports\"),\n",
        "    ckpt_dir=str(STORE / \"checkpoints\" / \"image_lenet\"),\n",
        "\n",
        "    img_size=32,\n",
        "    batch_size=128,\n",
        "    num_workers=4,\n",
        "    num_epochs=30,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "\n",
        "    use_amp=True,\n",
        "    dropout_rate=0.5,\n",
        "\n",
        "    force_colab_loader=True,  # Force Colab data loader\n",
        "\n",
        "    model_name=\"lenet_canonical\",\n",
        "    export_split=\"val\",\n",
        ")\n",
        "\n",
        "wandb.config.update(cfg.__dict__)\n",
        "\n",
        "try:\n",
        "\n",
        "    result = run_lenet_canonical(cfg)\n",
        "\n",
        "    print(\"EXPORT:\", result[\"export_result\"])\n",
        "    print(\"VERIFY:\", result[\"verify_metadata\"])\n",
        "    print(\"probs_shape:\", result[\"probs_shape\"])\n",
        "    print(\"best_val_f1:\", result[\"best_val_f1\"])\n",
        "\n",
        "    wandb.log({\"best_val_f1\": result[\"best_val_f1\"]})\n",
        "\n",
        "finally:\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cell-9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-9",
        "outputId": "a8fe97aa-6391-4acb-8275-5d0931fbcbdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export dir: /content/drive/MyDrive/DS_rakuten_store/artifacts/exports/lenet_canonical\n",
            "Contents: ['val.npz', 'val_meta.json']\n",
            "✓ Export files exist.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "STORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\n",
        "export_dir = STORE / \"artifacts\" / \"exports\" / \"lenet_canonical\"\n",
        "\n",
        "print(\"Export dir:\", export_dir)\n",
        "print(\"Contents:\", [p.name for p in export_dir.glob(\"*\")])\n",
        "\n",
        "assert (export_dir / \"val.npz\").exists(), \"Missing val.npz\"\n",
        "assert (export_dir / \"val_meta.json\").exists(), \"Missing val_meta.json\"\n",
        "print(\"✓ Export files exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cell-10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-10",
        "outputId": "8446a13d-6255-46ff-9f20-4b5170099890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'apps.image_app.scripts.validate_exports' (ModuleNotFoundError: No module named 'apps')\n"
          ]
        }
      ],
      "source": [
        "!python -m apps.image_app.scripts.validate_exports --split val --exports-root \"$DS_RAKUTEN_STORE/artifacts/exports\" --strict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cell-11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-11",
        "outputId": "3030d4ea-edf0-4739-c53d-b4f0ab297a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name: lenet_canonical\n",
            "split_name: val\n",
            "split_signature: cf53f8eb169b3531\n",
            "classes_fp: cdfa70b13f7390e6\n",
            "num_samples: 10827\n",
            "probs_shape: [10827, 27]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "STORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\n",
        "meta_path = STORE / \"artifacts\" / \"exports\" / \"lenet_canonical\" / \"val_meta.json\"\n",
        "\n",
        "meta = json.loads(meta_path.read_text())\n",
        "keys = [\n",
        "    \"model_name\", \"split_name\", \"split_signature\",\n",
        "    \"classes_fp\", \"num_samples\", \"probs_shape\"\n",
        "]\n",
        "for k in keys:\n",
        "    print(f\"{k}: {meta.get(k)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cell-12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-12",
        "outputId": "ba0d79b4-6018-40c5-84f7-a03a56e3e4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ loaded ok\n",
            "model: lenet_canonical\n",
            "split: val\n",
            "sig: cf53f8eb169b3531\n",
            "fp: cdfa70b13f7390e6\n",
            "probs: (10827, 27)\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "from src.export.model_exporter import load_predictions\n",
        "from src.data.label_mapping import CANONICAL_CLASSES_FP\n",
        "from src.data.split_manager import load_splits, split_signature\n",
        "\n",
        "splits = load_splits(verbose=False)\n",
        "sig = split_signature(splits)\n",
        "\n",
        "CACHE = Path(\"/content/cache_exports\")\n",
        "CACHE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "export_result = result[\"export_result\"]\n",
        "npz_src = Path(export_result[\"npz_path\"])\n",
        "meta_src = npz_src.with_name(npz_src.stem + \"_meta.json\")\n",
        "\n",
        "npz_local = CACHE / npz_src.name\n",
        "meta_local = CACHE / meta_src.name\n",
        "\n",
        "# Copy both files (npz + meta)\n",
        "if (not npz_local.exists()) or (npz_local.stat().st_size != npz_src.stat().st_size):\n",
        "    shutil.copy2(npz_src, npz_local)\n",
        "\n",
        "if (not meta_local.exists()) or (meta_local.stat().st_size != meta_src.stat().st_size):\n",
        "    shutil.copy2(meta_src, meta_local)\n",
        "\n",
        "loaded = load_predictions(\n",
        "    npz_path=str(npz_local),\n",
        "    verify_split_signature=sig,\n",
        "    verify_classes_fp=CANONICAL_CLASSES_FP,\n",
        "    require_y_true=True,\n",
        ")\n",
        "\n",
        "print(\"✓ loaded ok\")\n",
        "print(\"model:\", loaded[\"metadata\"][\"model_name\"])\n",
        "print(\"split:\", loaded[\"metadata\"][\"split_name\"])\n",
        "print(\"sig:\", loaded[\"metadata\"][\"split_signature\"])\n",
        "print(\"fp:\", loaded[\"metadata\"][\"classes_fp\"])\n",
        "print(\"probs:\", loaded[\"probs\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cell-13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-13",
        "outputId": "267e1923-81a4-4539-d39d-22716d45dbf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export dir: /content/drive/MyDrive/DS_rakuten_store/artifacts/exports/lenet_canonical\n",
            "Files: ['val.npz', 'val_meta.json']\n",
            "✓ Export files exist\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "STORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\n",
        "export_dir = STORE / \"artifacts\" / \"exports\" / \"lenet_canonical\"\n",
        "\n",
        "print(\"Export dir:\", export_dir)\n",
        "print(\"Files:\", [p.name for p in export_dir.glob(\"*\")])\n",
        "\n",
        "assert (export_dir / \"val.npz\").exists(), \"Missing val.npz\"\n",
        "assert (export_dir / \"val_meta.json\").exists(), \"Missing val_meta.json\"\n",
        "print(\"✓ Export files exist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cell-14",
      "metadata": {
        "id": "cell-14"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}