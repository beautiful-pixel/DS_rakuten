{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21552,
     "status": "ok",
     "timestamp": 1768058406892,
     "user": {
      "displayName": "Xiaosong",
      "userId": "17867917245160544832"
     },
     "user_tz": -60
    },
    "id": "WbQUwkw-kyla",
    "outputId": "8d2e126e-686f-486d-d9b5-be924badccce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "✓ DRIVE_CODE_SNAPSHOT: /content/drive/MyDrive/DS_rakuten_colab\n",
      "✓ DRIVE_STORE: /content/drive/MyDrive/DS_rakuten_store\n",
      "✓ DRIVE_SPLITS_SRC: /content/drive/MyDrive/DS_rakuten_store/splits\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "DRIVE_CODE_SNAPSHOT = Path(\"/content/drive/MyDrive/DS_rakuten_colab\")\n",
    "DRIVE_STORE = Path(\"/content/drive/MyDrive/DS_rakuten_store\")\n",
    "DRIVE_SPLITS_SRC = DRIVE_STORE / \"splits\"   # expects train_idx.txt / val_idx.txt / test_idx.txt\n",
    "\n",
    "assert DRIVE_CODE_SNAPSHOT.exists(), f\"Missing code snapshot: {DRIVE_CODE_SNAPSHOT}\"\n",
    "DRIVE_STORE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"DS_RAKUTEN_STORE\"] = str(DRIVE_STORE)\n",
    "\n",
    "print(\"✓ DRIVE_CODE_SNAPSHOT:\", DRIVE_CODE_SNAPSHOT)\n",
    "print(\"✓ DRIVE_STORE:\", DRIVE_STORE)\n",
    "print(\"✓ DRIVE_SPLITS_SRC:\", DRIVE_SPLITS_SRC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107145,
     "status": "ok",
     "timestamp": 1768058514040,
     "user": {
      "displayName": "Xiaosong",
      "userId": "17867917245160544832"
     },
     "user_tz": -60
    },
    "id": "MOmV19_bqSHC",
    "outputId": "7e104bc5-ede3-4811-f14e-78a1313eb9ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Runtime code ready: /content/DS_rakuten\n",
      "✓ sys.path[0]: /content/DS_rakuten\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "RUNTIME_ROOT = Path(\"/content/DS_rakuten\")\n",
    "\n",
    "# Clean and copy for deterministic imports\n",
    "if RUNTIME_ROOT.exists():\n",
    "    shutil.rmtree(RUNTIME_ROOT)\n",
    "\n",
    "shutil.copytree(DRIVE_CODE_SNAPSHOT, RUNTIME_ROOT)\n",
    "\n",
    "sys.path.insert(0, str(RUNTIME_ROOT))\n",
    "\n",
    "print(\"✓ Runtime code ready:\", RUNTIME_ROOT)\n",
    "print(\"✓ sys.path[0]:\", sys.path[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4607,
     "status": "ok",
     "timestamp": 1768058518645,
     "user": {
      "displayName": "Xiaosong",
      "userId": "17867917245160544832"
     },
     "user_tz": -60
    },
    "id": "oEUO5x3WqT2z",
    "outputId": "7ddfaf80-69e9-46d0-b400-46e4d74a0a32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Splits synced to: /content/DS_rakuten/data/splits\n",
      "✓ Contents: [PosixPath('/content/DS_rakuten/data/splits/test_idx.txt'), PosixPath('/content/DS_rakuten/data/splits/val_idx.txt'), PosixPath('/content/DS_rakuten/data/splits/train_idx.txt')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "runtime_splits_dir = Path(\"/content/DS_rakuten/data/splits\")\n",
    "runtime_splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy txt files from Drive persistent store into /content runtime repo\n",
    "src_files = [\"train_idx.txt\", \"val_idx.txt\", \"test_idx.txt\"]\n",
    "for fn in src_files:\n",
    "    src = DRIVE_SPLITS_SRC / fn\n",
    "    dst = runtime_splits_dir / fn\n",
    "    assert src.exists(), f\"Missing split file in Drive: {src}\"\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "print(\"✓ Splits synced to:\", runtime_splits_dir)\n",
    "print(\"✓ Contents:\", list(runtime_splits_dir.glob(\"*.txt\"))[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64209,
     "status": "ok",
     "timestamp": 1768058582864,
     "user": {
      "displayName": "Xiaosong",
      "userId": "17867917245160544832"
     },
     "user_tz": -60
    },
    "id": "2yv5djcAqYDa",
    "outputId": "ea658397-6862-4dc4-9da9-8647a6d3351f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images zip...\n",
      "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=15ZkS0iTQ7j3mHpxil4mABlXwP-jAN_zi\n",
      "From (redirected): https://drive.google.com/uc?id=15ZkS0iTQ7j3mHpxil4mABlXwP-jAN_zi&confirm=t&uuid=e05412bd-c284-4066-b7b9-26f1e1443806\n",
      "To: /content/tmp/images.zip\n",
      "100% 2.56G/2.56G [00:32<00:00, 78.7MB/s]\n",
      "Unzipping images...\n",
      "✓ IMG_ROOT detected: /content/images/images/image_train\n",
      "✓ sample jpg: /content/images/images/image_train/image_1010030825_product_443748930.jpg\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGE_FILE_ID = \"15ZkS0iTQ7j3mHpxil4mABlXwP-jAN_zi\"\n",
    "\n",
    "BASE_DIR = Path(\"/content/images\")\n",
    "TMP_DIR = Path(\"/content/tmp\")\n",
    "ZIP_PATH = TMP_DIR / \"images.zip\"\n",
    "\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not ZIP_PATH.exists():\n",
    "    print(\"Downloading images zip...\")\n",
    "    !gdown --id $IMAGE_FILE_ID -O {str(ZIP_PATH)}\n",
    "else:\n",
    "    print(\"Zip already present:\", ZIP_PATH)\n",
    "\n",
    "print(\"Unzipping images...\")\n",
    "!unzip -q -o {str(ZIP_PATH)} -d {str(BASE_DIR)}\n",
    "\n",
    "def count_jpgs(p: Path, limit: int = 2000) -> int:\n",
    "    if not p.exists():\n",
    "        return 0\n",
    "    n = 0\n",
    "    for _ in p.rglob(\"*.jpg\"):\n",
    "        n += 1\n",
    "        if n >= limit:\n",
    "            break\n",
    "    return n\n",
    "\n",
    "# Common candidates\n",
    "candidates = [\n",
    "    BASE_DIR / \"images\" / \"image_train\",\n",
    "    BASE_DIR / \"image_train\",\n",
    "    BASE_DIR / \"images\" / \"images\" / \"image_train\",\n",
    "]\n",
    "\n",
    "best = None\n",
    "best_count = 0\n",
    "for c in candidates:\n",
    "    n = count_jpgs(c)\n",
    "    if n > best_count:\n",
    "        best, best_count = c, n\n",
    "\n",
    "# Fallback: search any folder named image_train\n",
    "if best_count == 0:\n",
    "    for c in BASE_DIR.rglob(\"image_train\"):\n",
    "        if c.is_dir():\n",
    "            n = count_jpgs(c)\n",
    "            if n > best_count:\n",
    "                best, best_count = c, n\n",
    "\n",
    "assert best is not None and best_count > 0, (\n",
    "    \"Could not find an image_train directory with jpg files under /content/images. \"\n",
    "    \"Check zip content and unzip path.\"\n",
    ")\n",
    "\n",
    "IMG_ROOT = best\n",
    "sample_jpg = next(IMG_ROOT.rglob(\"*.jpg\"))\n",
    "\n",
    "print(\"✓ IMG_ROOT detected:\", IMG_ROOT)\n",
    "print(\"✓ sample jpg:\", sample_jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12584,
     "status": "ok",
     "timestamp": 1768058595458,
     "user": {
      "displayName": "Xiaosong",
      "userId": "17867917245160544832"
     },
     "user_tz": -60
    },
    "id": "xoDxn1L91stu",
    "outputId": "e2344459-4d75-4dc1-9201-d0968c760ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RakutenImageDataset: <class 'src.data.image_dataset.RakutenImageDataset'>\n",
      "✓ ResNet50Config: <class 'src.train.image_resnet50.ResNet50Config'>\n",
      "✓ run_resnet50_colab: <function run_resnet50_colab at 0x7f965d8d1800>\n"
     ]
    }
   ],
   "source": [
    "from src.data.image_dataset import RakutenImageDataset\n",
    "from src.train.image_resnet50 import ResNet50Config, run_resnet50_colab\n",
    "\n",
    "print(\"✓ RakutenImageDataset:\", RakutenImageDataset)\n",
    "print(\"✓ ResNet50Config:\", ResNet50Config)\n",
    "print(\"✓ run_resnet50_colab:\", run_resnet50_colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1768058595466,
     "user": {
      "displayName": "Xiaosong",
      "userId": "17867917245160544832"
     },
     "user_tz": -60
    },
    "id": "3k1VpKR1qbLb",
    "outputId": "e9797b0d-0b8a-4782-b367-c6f1edec33f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[split_manager] Loading canonical splits from /content/DS_rakuten/data/splits\n",
      "✓ signature: cf53f8eb169b3531\n",
      "{'train_idx': 61351, 'val_idx': 10827, 'test_idx': 12738}\n"
     ]
    }
   ],
   "source": [
    "from src.data.split_manager import load_splits, split_signature\n",
    "\n",
    "splits = load_splits(verbose=True)\n",
    "sig = split_signature(splits)\n",
    "\n",
    "print(\"✓ signature:\", sig)\n",
    "print({k: len(v) for k, v in splits.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# EXPORT TEST LOGITS (without retraining)\n# Load pretrained checkpoint and export test set logits\n# ============================================================\n\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.models as tvm\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nfrom src.data.data_colab import load_data_colab\nfrom src.data.split_manager import load_splits, split_signature\nfrom src.data.label_mapping import (\n    CANONICAL_CLASSES,\n    CANONICAL_CLASSES_FP,\n    encode_labels,\n)\nfrom src.export.model_exporter import export_predictions, load_predictions\nfrom src.data.image_dataset import RakutenImageDataset\n\n# ---- Configuration ----\nSTORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\nCKPT_PATH = STORE / \"checkpoints\" / \"image_resnet50\" / \"best_model.pth\"\nOUT_DIR = STORE / \"artifacts\" / \"exports\"\nRAW_DIR = \"/content/drive/MyDrive/DS_rakuten_store/data_raw\"\n\nIMG_SIZE = 224\nBATCH_SIZE = 1024\nNUM_CLASSES = 27\nDROPOUT_RATE = 0.5\nMODEL_NAME = \"resnet50\"  # Export to same folder as val.npz\n\nprint(\"=\" * 60)\nprint(\"EXPORT TEST LOGITS - ResNet50\")\nprint(\"=\" * 60)\nprint(f\"Checkpoint: {CKPT_PATH}\")\nprint(f\"Output dir: {OUT_DIR}\")\n\n# ---- Verify checkpoint exists ----\nassert CKPT_PATH.exists(), f\"Checkpoint not found: {CKPT_PATH}\"\nprint(f\"✓ Checkpoint found: {CKPT_PATH}\")\n\n# ---- Build model architecture ----\ndef build_resnet50(num_classes: int, dropout_rate: float) -> nn.Module:\n    model = tvm.resnet50(weights=None)  # No pretrained weights needed\n    in_features = model.fc.in_features\n    model.fc = nn.Sequential(\n        nn.Dropout(p=float(dropout_rate)),\n        nn.Linear(in_features, int(num_classes)),\n    )\n    return model\n\n# ---- Load checkpoint ----\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\n\nmodel = build_resnet50(NUM_CLASSES, DROPOUT_RATE).to(device)\nckpt = torch.load(CKPT_PATH, map_location=device)\nmodel.load_state_dict(ckpt[\"model_state_dict\"])\nmodel.eval()\n\nprint(f\"✓ Model loaded from epoch {ckpt.get('epoch', '?')}\")\nprint(f\"✓ Best val F1: {ckpt.get('best_val_f1', '?'):.4f}\")\nprint(f\"✓ Split signature: {ckpt.get('split_signature', '?')}\")\n\n# ---- Load data ----\npack = load_data_colab(\n    raw_dir=RAW_DIR,\n    img_root=IMG_ROOT,\n    splitted=False,\n    verbose=True,\n)\nX, y = pack[\"X\"], pack[\"y\"]\n\n# ---- Splits and labels ----\nsplits = load_splits(verbose=True)\nsig = split_signature(splits)\ny_encoded = encode_labels(y, CANONICAL_CLASSES).astype(int)\n\nprint(f\"✓ Split signature: {sig}\")\nprint(f\"✓ Test set size: {len(splits['test_idx'])}\")\n\n# ---- Prepare test dataset ----\nval_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.CenterCrop(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\nfull_df = X.copy()\nfull_df[\"encoded_label\"] = y_encoded\n\n# IndexedDataset to track real indices\nclass IndexedDataset(Dataset):\n    def __init__(self, base_dataset: Dataset, indices: np.ndarray):\n        self.base = base_dataset\n        self.indices = np.asarray(indices).astype(int)\n\n    def __len__(self) -> int:\n        return len(self.indices)\n\n    def __getitem__(self, i: int):\n        real_idx = int(self.indices[i])\n        img, label = self.base[real_idx]\n        return img, label, real_idx\n\nfull_dataset = RakutenImageDataset(\n    dataframe=full_df.reset_index(drop=True),\n    image_dir=str(IMG_ROOT),\n    transform=val_transform,\n    label_col=\"encoded_label\",\n)\n\ntest_idx = splits[\"test_idx\"]\ntest_dataset = IndexedDataset(full_dataset, test_idx)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=0,  # Colab stability\n    pin_memory=device.startswith(\"cuda\"),\n)\n\nprint(f\"✓ Test DataLoader ready: {len(test_loader)} batches\")\n\n# ---- Inference: Extract LOGITS (not softmax probs) ----\n@torch.no_grad()\ndef predict_logits(model, loader, device):\n    model.eval()\n    logits_list = []\n    idx_list = []\n    \n    for images, _, real_idx in tqdm(loader, desc=\"Test Inference\", ncols=100):\n        images = images.to(device, non_blocking=True)\n        logits = model(images)  # Raw logits, NO softmax\n        logits_list.append(logits.detach().cpu().numpy())\n        idx_list.append(real_idx.detach().cpu().numpy())\n    \n    logits = np.concatenate(logits_list, axis=0)\n    idx = np.concatenate(idx_list, axis=0)\n    return logits, idx\n\nprint(\"Running inference on test set...\")\ntest_logits, seen_idx = predict_logits(model, test_loader, device)\n\n# ---- Verify alignment ----\nif not np.array_equal(seen_idx, test_idx):\n    raise AssertionError(\"Index order mismatch during test inference!\")\n\nprint(f\"✓ Inference complete: logits shape = {test_logits.shape}\")\n\n# ---- Get y_true for test set ----\ny_true_test = y_encoded[test_idx].astype(int)\n\n# ---- Export test logits ----\nexport_result = export_predictions(\n    out_dir=OUT_DIR,\n    model_name=MODEL_NAME,\n    split_name=\"test\",\n    idx=seen_idx,\n    split_signature=sig,\n    logits=test_logits,  # Export LOGITS, not probs\n    classes=CANONICAL_CLASSES,\n    y_true=y_true_test,\n    extra_meta={\n        \"source\": \"image_03_resnet50_logits.ipynb\",\n        \"model_architecture\": \"torchvision.resnet50\",\n        \"img_dir\": str(IMG_ROOT),\n        \"img_size\": IMG_SIZE,\n        \"batch_size\": BATCH_SIZE,\n        \"dropout_rate\": DROPOUT_RATE,\n        \"output_type\": \"logits\",\n        \"checkpoint_path\": str(CKPT_PATH),\n        \"classes_fp\": CANONICAL_CLASSES_FP,\n        \"split_signature\": sig,\n    },\n)\n\nprint()\nprint(\"=\" * 60)\nprint(\"EXPORT COMPLETE\")\nprint(\"=\" * 60)\nprint(f\"NPZ path: {export_result['npz_path']}\")\nprint(f\"Meta JSON: {export_result['meta_json_path']}\")\nprint(f\"Samples: {export_result['num_samples']}\")\nprint(f\"Split signature: {export_result['split_signature']}\")\n\n# ---- Verify export ----\nloaded = load_predictions(\n    npz_path=export_result[\"npz_path\"],\n    verify_split_signature=sig,\n    verify_classes_fp=CANONICAL_CLASSES_FP,\n    require_y_true=True,\n)\n\nprint()\nprint(\"✓ Export verification passed!\")\nprint(f\"  - model: {loaded['metadata']['model_name']}\")\nprint(f\"  - split: {loaded['metadata']['split_name']}\")\nprint(f\"  - output_type: {loaded['metadata'].get('output_type', 'probs')}\")\nprint(f\"  - logits shape: {loaded['logits'].shape}\")\nprint(f\"  - has_y_true: {loaded['metadata']['has_y_true']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2811604,
     "status": "ok",
     "timestamp": 1768061407076,
     "user": {
      "displayName": "Xiaosong",
      "userId": "17867917245160544832"
     },
     "user_tz": -60
    },
    "id": "Tx2UpXUjqd1S",
    "outputId": "ef44bace-9578-4b99-daf4-4236e5788ee2"
   },
   "outputs": [],
   "source": "# ============================================================\n# TRAINING CODE (SKIP - already trained)\n# ============================================================\n# The model has already been trained and checkpoint saved.\n# Run cell-6 above to export test logits without retraining.\n# \n# Original training code is commented out below for reference:\n# ------------------------------------------------------------\n# cfg = ResNet50Config(\n#     raw_dir=\"/content/drive/MyDrive/DS_rakuten_store/data_raw\",\n#     img_dir=str(IMG_ROOT),\n#     out_dir=str(STORE / \"artifacts\" / \"exports\"),\n#     ckpt_dir=str(STORE / \"checkpoints\" / \"image_resnet50\"),\n#     img_size=224,\n#     batch_size=1024,\n#     num_workers=12,\n#     num_epochs=30,\n#     lr=6e-4,\n#     use_amp=True,\n#     label_smoothing=0.1,\n#     dropout_rate=0.5,\n#     model_name=\"resnet50\",\n#     export_split=\"val\",\n# )\n# result = run_resnet50_colab(cfg)\nprint(\"Training code skipped - model already trained.\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}