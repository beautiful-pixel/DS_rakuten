{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ef35892-6830-4e5c-b16a-46fa5951f385",
   "metadata": {},
   "source": [
    "<div style=\"background:#f0f8ff; padding:14px; border-radius:6px\">\n",
    "\n",
    "<h2>I – Contexte et objectifs</h2>\n",
    "\n",
    "<p>\n",
    "Les étapes précédentes du projet ont permis d’explorer et de comparer différentes\n",
    "approches de classification <b>texte</b>, <b>image</b> et <b>multimodales</b>, à l’aide\n",
    "d’un <b>jeu de validation interne</b> dédié à l’analyse des performances et au\n",
    "choix des architectures.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Cette phase d’évaluation a conduit à la sélection d’un <b>modèle multimodal\n",
    "final</b> reposant sur :\n",
    "<ul>\n",
    "    <li>une <b>fusion texte</b> par blending de modèles calibrés,</li>\n",
    "    <li>une <b>fusion image</b> par blending de modèles deep learning,</li>\n",
    "    <li>un <b>méta-classifieur de stacking</b> combinant les deux modalités.</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "L’objectif de ce notebook est désormais différent : il ne s’agit plus de\n",
    "comparer des modèles, mais de <b>figer les choix effectués</b>, de\n",
    "<b>réentraîner les modèles dans un cadre finalisé</b> et de construire un\n",
    "<b>pipeline de prédiction complet</b> permettant de générer les sorties sur le\n",
    "jeu de test du challenge.\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background:#f0f8ff; padding:14px; border-radius:6px\">\n",
    "\n",
    "<h2>II – Stratégie de réentraînement final</h2>\n",
    "\n",
    "<p>\n",
    "Une fois les architectures, les hyperparamètres et les schémas de fusion\n",
    "définitivement sélectionnés, l’enjeu principal devient la\n",
    "<b>maximisation de l’information exploitée lors de l’entraînement final</b>,\n",
    "tout en évitant toute fuite de données.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "La stratégie retenue repose sur une <b>séparation claire des rôles</b> entre les\n",
    "différentes phases d’apprentissage :\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        Les <b>modèles de base</b> (texte et image) sont entraînés initialement sur\n",
    "        le <b>train interne</b>, avec un jeu de validation technique dédié au suivi\n",
    "        de l’apprentissage (early stopping, choix du nombre d’epochs).\n",
    "    </li>\n",
    "    <li>\n",
    "        Les <b>paramètres de calibration</b> (temperature scaling) ainsi que les\n",
    "        <b>poids des blendings</b> sont estimés sur les prédictions des modèles\n",
    "        figés, à partir du <b>jeu de validation interne</b>.\n",
    "    </li>\n",
    "    <li>\n",
    "        Le <b>méta-classifieur de stacking</b> est entraîné uniquement sur des\n",
    "        <b>probabilités calibrées</b>, issues des modèles de base, afin de garantir\n",
    "        une combinaison cohérente et stable des modalités.\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Une fois l’ensemble de ces paramètres figés, les modèles peuvent être\n",
    "<b>réentraînés sur un volume de données plus important</b> (train + validation\n",
    "interne), tout en conservant une petite validation technique pour les modèles\n",
    "deep learning. Le méta-modèle, lui, n’est plus modifié à ce stade.\n",
    "</p>\n",
    "\n",
    "<h2>III – Construction du pipeline de prédiction final</h2>\n",
    "\n",
    "<p>\n",
    "La dernière étape consiste à transformer les modèles entraînés en un\n",
    "<b>pipeline de prédiction unifié</b>, capable de produire une prédiction finale\n",
    "à partir des <b>données brutes du challenge</b>.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Ce pipeline multimodal s’organise en plusieurs niveaux hiérarchiques :\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        Un <b>pipeline texte</b> regroupant la vectorisation, les modèles\n",
    "        transformeurs et/ou classiques, la calibration des probabilités, puis la\n",
    "        fusion texte par blending.\n",
    "    </li>\n",
    "    <li>\n",
    "        Un <b>pipeline image</b> intégrant les transformations visuelles, les\n",
    "        modèles deep learning, la calibration, puis la fusion image par blending.\n",
    "    </li>\n",
    "    <li>\n",
    "        Un <b>méta-pipeline multimodal</b>, qui combine les sorties des pipelines\n",
    "        texte et image via le méta-classifieur de stacking.\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Cette organisation modulaire permet :\n",
    "<ul>\n",
    "    <li>une <b>reproductibilité complète</b> des prédictions,</li>\n",
    "    <li>une <b>séparation claire des responsabilités</b> entre modalités,</li>\n",
    "    <li>une <b>maintenance facilitée</b> du système (remplacement ou amélioration\n",
    "    d’un sous-modèle sans refonte globale).</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Le pipeline final constitue ainsi l’aboutissement du projet, reliant de manière\n",
    "cohérente l’exploration, l’analyse des performances, l’interprétabilité et la\n",
    "mise en production des prédictions sur le jeu de test non labellisé.\n",
    "</p>\n",
    "\n",
    "\n",
    "<h4>Pipeline multimodal final</h4>\n",
    "\n",
    "<img src=\"pipeline_final.png\"\n",
    "     alt=\"Pipeline multimodal\"\n",
    "     style=\"display:block; margin:auto; max-width:100%;\">\n",
    "\n",
    "<p style=\"text-align:center; font-size:13px; color:#555;\">\n",
    "Figure – Schéma du pipeline multimodal (texte, image et stacking).\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52391c4-5ab5-4648-974c-4b7bee5f5139",
   "metadata": {},
   "source": [
    "<div style=\"background:#f0f8ff; padding:14px; border-radius:6px\">\n",
    "\n",
    "<h2>IV – Stratégie de réentraînement final et figement du pipeline</h2>\n",
    "\n",
    "<p>\n",
    "Une fois le choix du modèle multimodal validé et les performances analysées sur\n",
    "le jeu de validation interne, une <b>stratégie de réentraînement final</b> est mise\n",
    "en place afin de maximiser l’utilisation des données disponibles tout en\n",
    "préservant la robustesse du pipeline.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Dans un premier temps, l’ensemble des <b>hyperparamètres de fusion</b> est\n",
    "recalculé à partir des prédictions des modèles entraînés sur le split initial :\n",
    "les <b>températures de calibration</b>, les <b>poids de blending</b> (déduits de la\n",
    "log loss) ainsi que le <b>méta-classifieur de stacking</b> sont ajustés en utilisant\n",
    "le <b>jeu de validation et le jeu de test interne</b>. Ce choix permet\n",
    "d’augmenter significativement le volume de données supervisées disponibles pour\n",
    "l’apprentissage du méta-modèle, sans introduire de fuite d’information vis-à-vis\n",
    "du jeu de test final du challenge.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Une fois ces paramètres figés, le pipeline multimodal est considéré comme\n",
    "<b>définitivement configuré</b>. Les modèles de base peuvent alors être\n",
    "<b>réentraînés sur l’ensemble des données disponibles</b> (train&nbsp;+&nbsp;validation&nbsp;+&nbsp;test\n",
    "interne) afin d’exploiter pleinement le corpus. Cette étape concerne en priorité\n",
    "les modèles de machine learning classiques (TF-IDF + SVM), dont le coût\n",
    "d’entraînement est modéré.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Pour certains modèles de deep learning, des <b>contraintes de temps et de\n",
    "ressources</b> peuvent conduire à conserver les poids issus de l’entraînement\n",
    "initial, ou à utiliser une validation technique réduite afin de contrôler\n",
    "l’arrêt de l’entraînement. Ce compromis permet de bénéficier d’un pipeline final\n",
    "cohérent et performant, tout en restant compatible avec les contraintes\n",
    "opérationnelles.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Cette stratégie assure ainsi une <b>séparation claire</b> entre la phase de\n",
    "sélection du modèle et celle de réentraînement final, tout en garantissant que\n",
    "le modèle soumis repose sur un pipeline entièrement figé et optimisé.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Nous allons donc maintenant <b>recalculer et enregistrer l’ensemble des\n",
    "paramètres finaux du pipeline</b>, incluant les <b>températures de calibration</b>,\n",
    "les <b>poids de blending</b> pour les fusions texte et image, ainsi que le\n",
    "<b>méta-classifieur de stacking</b>.\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e7e8d6-7045-4329-b698-58fdc21319e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../src')\n",
    "from data import load_data\n",
    "from utils.calibration import fit_temperature, calibrated_probas, normalize_probas, weights_from_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8445f0f-4495-4c06-962e-b77eef636313",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(splitted=True, encoded=True)\n",
    "y = np.hstack([data['y_val'], data['y_test']])\n",
    "\n",
    "# =========================\n",
    "# 1. IMAGE – Calibration + blending\n",
    "# =========================\n",
    "\n",
    "# --- ConvNeXt ---\n",
    "logits_val_cn = np.load(\"../predictions/image/logits_convnext_val.npz\")[\"logits\"]\n",
    "logits_test_cn = np.load(\"../predictions/image/logits_convnext_test.npz\")[\"logits\"]\n",
    "logits_cn = np.vstack([logits_val_cn, logits_test_cn])\n",
    "\n",
    "T_convnext = fit_temperature(logits_cn, y)\n",
    "P_convnext = calibrated_probas(logits_cn, T_convnext)\n",
    "\n",
    "# --- Swin ---\n",
    "logits_val_swin = np.load(\"../predictions/image/logits_swin_val.npz\")[\"logits\"]\n",
    "logits_test_swin = np.load(\"../predictions/image/logits_swin_test.npz\")[\"logits\"]\n",
    "logits_swin = np.vstack([logits_val_swin, logits_test_swin])\n",
    "\n",
    "T_swin = fit_temperature(logits_swin, y)\n",
    "P_swin = calibrated_probas(logits_swin, T_swin)\n",
    "\n",
    "# --- Image blending weights ---\n",
    "image_log_losses = {\n",
    "    \"convnext\": log_loss(y, P_convnext),\n",
    "    \"swin\": log_loss(y, P_swin),\n",
    "}\n",
    "image_weights = weights_from_logloss(image_log_losses)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. TEXTE – Calibration + blending\n",
    "# =========================\n",
    "\n",
    "# --- CamemBERT ---\n",
    "logits_val_cam = np.load(\"../predictions/text/logits_camembert_val.npy\")\n",
    "logits_test_cam = np.load(\"../predictions/text/logits_camembert_test.npy\")\n",
    "logits_cam = np.vstack([logits_val_cam, logits_test_cam])\n",
    "\n",
    "T_camembert = fit_temperature(logits_cam, y)\n",
    "P_camembert = calibrated_probas(logits_cam, T_camembert)\n",
    "\n",
    "# --- XLM-R ---\n",
    "logits_val_xlmr = np.load(\"../predictions/text/logits_xlmr_val.npy\")\n",
    "logits_test_xlmr = np.load(\"../predictions/text/logits_xlmr_test.npy\")\n",
    "logits_xlmr = np.vstack([logits_val_xlmr, logits_test_xlmr])\n",
    "\n",
    "T_xlmr = fit_temperature(logits_xlmr, y)\n",
    "P_xlmr = calibrated_probas(logits_xlmr, T_xlmr)\n",
    "\n",
    "# --- TF-IDF (déjà calibré) ---\n",
    "P_val_tfidf = np.load(\"../predictions/text/proba_vec_val.npy\")\n",
    "P_test_tfidf = np.load(\"../predictions/text/proba_vec_test.npy\")\n",
    "P_tfidf = np.vstack([P_val_tfidf, P_test_tfidf])\n",
    "\n",
    "# --- Text blending weights ---\n",
    "text_log_losses = {\n",
    "    \"camembert\": log_loss(y, P_camembert),\n",
    "    \"xlmr\": log_loss(y, P_xlmr),\n",
    "    \"tfidf\": log_loss(y, P_tfidf),\n",
    "}\n",
    "text_weights = weights_from_logloss(text_log_losses)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. Sauvegarde des paramètres globaux\n",
    "# =========================\n",
    "\n",
    "fusion_params = {\n",
    "    \"image\": {\n",
    "        \"temperatures\": {\n",
    "            \"convnext\": float(T_convnext),\n",
    "            \"swin\": float(T_swin),\n",
    "        },\n",
    "        \"weights\": {\n",
    "            \"convnext\": float(image_weights[\"convnext\"]),\n",
    "            \"swin\": float(image_weights[\"swin\"]),\n",
    "        },\n",
    "    },\n",
    "    \"text\": {\n",
    "        \"temperatures\": {\n",
    "            \"camembert\": float(T_camembert),\n",
    "            \"xlmr\": float(T_xlmr),\n",
    "        },\n",
    "        \"weights\": {\n",
    "            \"camembert\": float(text_weights[\"camembert\"]),\n",
    "            \"xlmr\": float(text_weights[\"xlmr\"]),\n",
    "            \"tfidf\": float(text_weights[\"tfidf\"]),\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"../models/final/fusion_params.json\", \"w\") as f:\n",
    "    json.dump(fusion_params, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9a20b2e-aee5-4d8e-8a20-1f23c18d2a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/fusion/final/meta_model.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_txt = (\n",
    "    text_weights[\"camembert\"] * P_camembert\n",
    "    + text_weights[\"xlmr\"] * P_xlmr\n",
    "    + text_weights[\"tfidf\"] * P_tfidf\n",
    ")\n",
    "\n",
    "P_txt = normalize_probas(P_txt)\n",
    "\n",
    "P_im = (\n",
    "    image_weights[\"convnext\"] * P_convnext\n",
    "    + image_weights[\"swin\"] * P_swin\n",
    ")\n",
    "\n",
    "P_im = normalize_probas(P_im)\n",
    "\n",
    "X_meta = np.concatenate([P_txt, P_im], axis=1)\n",
    "\n",
    "meta_model = joblib.load(\n",
    "    \"../models/fusion/multimodal/meta_model_stacking.joblib\"\n",
    ")\n",
    "\n",
    "meta_model.fit(X_meta, y)\n",
    "\n",
    "joblib.dump(\n",
    "    meta_model,\n",
    "    \"../models/final/meta_model.joblib\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "422cd7f5-3edc-4e30-b20d-74743c1aa07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full, y_full = load_data(encoded=True).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fdaf51b-3424-46b3-9e0e-733e47e1ee6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/final/vectorizer_svm.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = joblib.load(\"../models/text/vectorizer_svm/vectorizer_svm_calibrated.joblib\")\n",
    "\n",
    "svm.fit(X_full, y_full)\n",
    "\n",
    "joblib.dump(\n",
    "    svm,\n",
    "    \"../models/final/vectorizer_svm.joblib\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6519f59-5b23-4dbc-abc2-1469978dd30a",
   "metadata": {},
   "source": [
    "<div style=\"background:#f0f8ff; padding:14px; border-radius:6px\">\n",
    "\n",
    "<h2>V – Pipeline final</h2>\n",
    "\n",
    "<p>\n",
    "À ce stade, l’ensemble des composants du modèle final est donc disponible sous\n",
    "forme persistée&nbsp;: modèles de base, paramètres de calibration, poids de\n",
    "blending et méta-classifieur. Ces éléments constituent les <b>briques\n",
    "fondamentales du pipeline multimodal final</b>.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "La section suivante est dédiée à la <b>construction explicite du pipeline\n",
    "d’inférence</b>. Celui-ci s’organise autour de trois niveaux&nbsp;:\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        un <b>pipeline texte</b>, combinant les prédictions issues des modèles\n",
    "        transformers et du modèle TF-IDF calibré via un blending pondéré&nbsp;;\n",
    "    </li>\n",
    "    <li>\n",
    "        un <b>pipeline image</b>, fusionnant les sorties des modèles ConvNeXt et\n",
    "        Swin à l’aide d’un blending calibré&nbsp;;\n",
    "    </li>\n",
    "    <li>\n",
    "        un <b>pipeline multimodal final</b>, qui agrège les probabilités issues des\n",
    "        deux modalités à l’aide du <b>méta-classifieur de stacking</b>.\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "L’architecture complète de ce pipeline, ainsi que les choix d’implémentation\n",
    "associés, sont détaillés dans la documentation du code&nbsp;:\n",
    "<br>\n",
    "<b>[Lien vers la documentation du pipeline à insérer ici]</b>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Une fois ce pipeline construit, il peut être utilisé comme un <b>modèle unique\n",
    "de bout en bout</b>, prenant en entrée des données brutes (texte et image) et\n",
    "produisant directement une prédiction finale. La dernière étape consiste donc à\n",
    "<b>tester ce pipeline complet</b> sur plusieurs exemples afin de vérifier son bon\n",
    "fonctionnement, sa cohérence et sa capacité à reproduire fidèlement les\n",
    "résultats obtenus lors de l’évaluation.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57cc04bc-ae4c-468a-9b17-c99cf4a8e6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertModel were not initialized from the model checkpoint at almanach/camembert-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "from pipeline.multimodal import FinalPipeline\n",
    "\n",
    "df = pd.read_csv('../data/raw/X_test_update.csv')\n",
    "model = FinalPipeline('../data/raw/images/image_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ec75038-8f92-4db0-ab3f-20eeaba0cb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84916</td>\n",
       "      <td>Folkmanis Puppets - 2732 - Marionnette Et Théâ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>516376098</td>\n",
       "      <td>1019294171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84917</td>\n",
       "      <td>Porte Flamme Gaxix - Flamebringer Gaxix - 136/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133389013</td>\n",
       "      <td>1274228667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84918</td>\n",
       "      <td>Pompe de filtration Speck Badu 95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4128438366</td>\n",
       "      <td>1295960357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84919</td>\n",
       "      <td>Robot de piscine électrique</td>\n",
       "      <td>&lt;p&gt;Ce robot de piscine d&amp;#39;un design innovan...</td>\n",
       "      <td>3929899732</td>\n",
       "      <td>1265224052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84920</td>\n",
       "      <td>Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152993898</td>\n",
       "      <td>940543690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        designation  \\\n",
       "0       84916  Folkmanis Puppets - 2732 - Marionnette Et Théâ...   \n",
       "1       84917  Porte Flamme Gaxix - Flamebringer Gaxix - 136/...   \n",
       "2       84918                  Pompe de filtration Speck Badu 95   \n",
       "3       84919                        Robot de piscine électrique   \n",
       "4       84920  Hsm Destructeur Securio C16 Coupe Crois¿E: 4 X...   \n",
       "\n",
       "                                         description   productid     imageid  \n",
       "0                                                NaN   516376098  1019294171  \n",
       "1                                                NaN   133389013  1274228667  \n",
       "2                                                NaN  4128438366  1295960357  \n",
       "3  <p>Ce robot de piscine d&#39;un design innovan...  3929899732  1265224052  \n",
       "4                                                NaN   152993898   940543690  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e637b857-c188-45e6-830f-51c262ce8765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1280, 1160, 2583, 2583, 2522], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_labels(df.iloc[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
