{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0cbf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f5de38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>designation_cleaned</th>\n",
       "      <th>description_cleaned</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>dup_count</th>\n",
       "      <th>is_duplicated_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>10</td>\n",
       "      <td>olivia: personalisiertes notizbuch 150 seiten ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>olivia: personalisiertes notizbuch 150 seiten ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>2280</td>\n",
       "      <td>journal arts (le) n° 133 28/09/2001 l'art marc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>journal arts (le) n° 133 28/09/2001 l'art marc...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>50</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "      <td>pilot style touch pen marque speedlink stylet ...</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>1280</td>\n",
       "      <td>peluche donald europe disneyland 2000 (marionn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peluche donald europe disneyland 2000 (marionn...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>2705</td>\n",
       "      <td>guerre tuques</td>\n",
       "      <td>luc idées grandeur veut organiser jeu guerre b...</td>\n",
       "      <td>guerre tuques luc idées grandeur veut organise...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    productid     imageid  prdtypecode  \\\n",
       "0  3804725264  1263597046           10   \n",
       "1   436067568  1008141237         2280   \n",
       "2   201115110   938777978           50   \n",
       "3    50418756   457047496         1280   \n",
       "4   278535884  1077757786         2705   \n",
       "\n",
       "                                 designation_cleaned  \\\n",
       "0  olivia: personalisiertes notizbuch 150 seiten ...   \n",
       "1  journal arts (le) n° 133 28/09/2001 l'art marc...   \n",
       "2  grand stylet ergonomique bleu gamepad nintendo...   \n",
       "3  peluche donald europe disneyland 2000 (marionn...   \n",
       "4                                      guerre tuques   \n",
       "\n",
       "                                 description_cleaned  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  pilot style touch pen marque speedlink stylet ...   \n",
       "3                                                NaN   \n",
       "4  luc idées grandeur veut organiser jeu guerre b...   \n",
       "\n",
       "                                        text_cleaned  dup_count  \\\n",
       "0  olivia: personalisiertes notizbuch 150 seiten ...          1   \n",
       "1  journal arts (le) n° 133 28/09/2001 l'art marc...          1   \n",
       "2  grand stylet ergonomique bleu gamepad nintendo...          1   \n",
       "3  peluche donald europe disneyland 2000 (marionn...          1   \n",
       "4  guerre tuques luc idées grandeur veut organise...          1   \n",
       "\n",
       "   is_duplicated_group  \n",
       "0                False  \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adapter le chemin vers le fichier CSV nettoyé produit par le notebook 01_xiaosong_text_clean.ipynb\n",
    "df = pd.read_csv(\"rakuten_text_train_v1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44cc519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_str(x):\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    return str(x)\n",
    "\n",
    "df[\"designation_cleaned\"] = df[\"designation_cleaned\"].fillna(\"\").apply(safe_str)\n",
    "df[\"description_cleaned\"] = df[\"description_cleaned\"].fillna(\"\").apply(safe_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dffe2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF titre - forme : (84916, 20000)\n",
      "TF-IDF description - forme : (84916, 30000)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF pour le titre\n",
    "tfidf_title = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    lowercase=False,\n",
    "    tokenizer=str.split,\n",
    ")\n",
    "\n",
    "X_tfidf_title = tfidf_title.fit_transform(df[\"designation_cleaned\"])\n",
    "print(\"TF-IDF titre - forme :\", X_tfidf_title.shape)\n",
    "\n",
    "# TF-IDF pour la description\n",
    "tfidf_desc = TfidfVectorizer(\n",
    "    max_features=30000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    lowercase=False,\n",
    "    tokenizer=str.split,\n",
    ")\n",
    "\n",
    "X_tfidf_desc = tfidf_desc.fit_transform(df[\"description_cleaned\"])\n",
    "print(\"TF-IDF description - forme :\", X_tfidf_desc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8ae560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation_cleaned_len_char</th>\n",
       "      <th>designation_cleaned_len_tokens</th>\n",
       "      <th>description_cleaned_len_char</th>\n",
       "      <th>description_cleaned_len_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>546</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   designation_cleaned_len_char  designation_cleaned_len_tokens  \\\n",
       "0                            80                              10   \n",
       "1                           161                              24   \n",
       "2                            72                              10   \n",
       "3                            57                               7   \n",
       "4                            13                               2   \n",
       "\n",
       "   description_cleaned_len_char  description_cleaned_len_tokens  \n",
       "0                             0                               0  \n",
       "1                             0                               0  \n",
       "2                           546                              70  \n",
       "3                             0                               0  \n",
       "4                           127                              18  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features structurales sur le texte\n",
    "\n",
    "UNIT_PATTERN = re.compile(r\"\\b\\d+\\s*(cm|mm|kg|g|ml|l|m)\\b\", flags=re.IGNORECASE)\n",
    "MULT_PATTERN = re.compile(r\"\\bx\\s*\\d+\\b|\\b\\d+\\s*x\\b\", flags=re.IGNORECASE)\n",
    "DIGIT_PATTERN = re.compile(r\"\\d\")\n",
    "\n",
    "def structural_stats(s: str) -> dict:\n",
    "    \"\"\"Calcule des indicateurs simples de structure.\"\"\"\n",
    "    s = safe_str(s)\n",
    "    tokens = s.split()\n",
    "    length_char = len(s)\n",
    "    length_tokens = len(tokens)\n",
    "    \n",
    "    num_digits = len(DIGIT_PATTERN.findall(s))\n",
    "    num_units = len(UNIT_PATTERN.findall(s))\n",
    "    num_mult = len(MULT_PATTERN.findall(s))\n",
    "    \n",
    "    return {\n",
    "        \"len_char\": length_char,\n",
    "        \"len_tokens\": length_tokens,\n",
    "        \"num_digits\": num_digits,\n",
    "        \"num_units\": num_units,\n",
    "        \"num_mult_pattern\": num_mult,\n",
    "    }\n",
    "\n",
    "# Application sur le titre et la description\n",
    "for col in [\"designation_cleaned\", \"description_cleaned\"]:\n",
    "    stats_series = df[col].apply(structural_stats)\n",
    "    stats_df = pd.DataFrame(list(stats_series))\n",
    "    for c in stats_df.columns:\n",
    "        df[f\"{col}_{c}\"] = stats_df[c]\n",
    "\n",
    "# Aperçu de quelques features de longueur\n",
    "df[\n",
    "    [\n",
    "        \"designation_cleaned_len_char\",\n",
    "        \"designation_cleaned_len_tokens\",\n",
    "        \"description_cleaned_len_char\",\n",
    "        \"description_cleaned_len_tokens\",\n",
    "    ]\n",
    "].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac54ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF titre  : (84916, 20000)\n",
      "TF-IDF desc   : (84916, 30000)\n",
      "Nombre de features numériques (structure + sémantique) : 10\n",
      "['designation_cleaned_len_char', 'designation_cleaned_len_tokens', 'designation_cleaned_num_digits', 'designation_cleaned_num_units', 'designation_cleaned_num_mult_pattern', 'description_cleaned_len_char', 'description_cleaned_len_tokens', 'description_cleaned_num_digits', 'description_cleaned_num_units', 'description_cleaned_num_mult_pattern']\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF titre  :\", X_tfidf_title.shape)\n",
    "print(\"TF-IDF desc   :\", X_tfidf_desc.shape)\n",
    "\n",
    "feature_cols = [\n",
    "    c for c in df.columns\n",
    "    if c.startswith(\"designation_cleaned_\")\n",
    "    or c.startswith(\"description_cleaned_\")\n",
    "]\n",
    "\n",
    "kw_cols = [c for c in df.columns if c.startswith(\"kw_\")]\n",
    "\n",
    "print(\"Nombre de features numériques (structure + sémantique) :\", len(feature_cols))\n",
    "print(feature_cols[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256edda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocess',\n",
      "                 ColumnTransformer(transformers=[('title_tfidf',\n",
      "                                                  TfidfVectorizer(lowercase=False,\n",
      "                                                                  max_df=0.8,\n",
      "                                                                  max_features=20000,\n",
      "                                                                  min_df=5,\n",
      "                                                                  ngram_range=(1,\n",
      "                                                                               3),\n",
      "                                                                  tokenizer=<method 'split' of 'str' objects>),\n",
      "                                                  'designation_cleaned'),\n",
      "                                                 ('desc_tfidf',\n",
      "                                                  TfidfVectorizer(lowercase=False,\n",
      "                                                                  max_df=0.8,\n",
      "                                                                  max_features=30000,\n",
      "                                                                  min_df=5,\n",
      "                                                                  ngram_range=(1,\n",
      "                                                                               3),\n",
      "                                                                  tokenizer=<method...\n",
      "                                                   'designation_cleaned_num_digits',\n",
      "                                                   'designation_cleaned_num_units',\n",
      "                                                   'designation_cleaned_num_mult_pattern',\n",
      "                                                   'description_cleaned_len_char',\n",
      "                                                   'description_cleaned_len_tokens',\n",
      "                                                   'description_cleaned_num_digits',\n",
      "                                                   'description_cleaned_num_units',\n",
      "                                                   'description_cleaned_num_mult_pattern'])])),\n",
      "                ('model',\n",
      "                 LogisticRegression(class_weight='balanced', max_iter=1000,\n",
      "                                    n_jobs=-1, solver='saga'))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Standardisation des features numériques\n",
    "num_scaler = StandardScaler(with_mean=False)  # with_mean=False pour matrices creuses\n",
    "\n",
    "meta_cols = feature_cols\n",
    "\n",
    "struct_cols = [\n",
    "    c for c in df.columns\n",
    "    if c.startswith(\"designation_cleaned_\")\n",
    "    or c.startswith(\"description_cleaned_\")\n",
    "]\n",
    "\n",
    "kw_cols = [c for c in df.columns if c.startswith(\"kw_\")]\n",
    "\n",
    "meta_cols = struct_cols\n",
    "\n",
    "# ColumnTransformer : combine texte (TF-IDF) + features numériques\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"title_tfidf\", tfidf_title, \"designation_cleaned\"),\n",
    "        (\"desc_tfidf\", tfidf_desc, \"description_cleaned\"),\n",
    "        (\"numeric\", num_scaler, meta_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.3,\n",
    ")\n",
    "\n",
    "# Modèle : Régression Logistique multiclasse\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",  # important pour les classes déséquilibrées\n",
    "    solver=\"saga\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Pipeline complet : prétraitement + modèle\n",
    "clf_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\", log_reg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(clf_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d778e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille X_train : (67932, 12)\n",
      "Taille X_valid : (16984, 12)\n",
      "Entraînement du modèle (pipeline complet)...\n",
      "\n",
      "Weighted F1 (validation) : 0.7707\n",
      "\n",
      "Classification report :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.33      0.73      0.45       623\n",
      "          40       0.76      0.59      0.66       502\n",
      "          50       0.78      0.80      0.79       336\n",
      "          60       0.88      0.76      0.82       166\n",
      "        1140       0.70      0.80      0.74       534\n",
      "        1160       0.80      0.90      0.85       791\n",
      "        1180       0.56      0.58      0.57       153\n",
      "        1280       0.76      0.48      0.59       974\n",
      "        1281       0.57      0.56      0.57       414\n",
      "        1300       0.83      0.85      0.84      1009\n",
      "        1301       0.94      0.94      0.94       161\n",
      "        1302       0.79      0.72      0.75       498\n",
      "        1320       0.77      0.65      0.70       648\n",
      "        1560       0.83      0.76      0.79      1015\n",
      "        1920       0.88      0.87      0.88       861\n",
      "        1940       0.67      0.94      0.78       161\n",
      "        2060       0.78      0.75      0.76       999\n",
      "        2220       0.76      0.84      0.80       165\n",
      "        2280       0.82      0.80      0.81       952\n",
      "        2403       0.69      0.68      0.68       955\n",
      "        2462       0.70      0.80      0.75       284\n",
      "        2522       0.91      0.83      0.87       998\n",
      "        2582       0.67      0.71      0.69       518\n",
      "        2583       0.98      0.89      0.93      2042\n",
      "        2585       0.74      0.76      0.75       499\n",
      "        2705       0.75      0.66      0.71       552\n",
      "        2905       0.98      0.99      0.98       174\n",
      "\n",
      "    accuracy                           0.77     16984\n",
      "   macro avg       0.76      0.76      0.76     16984\n",
      "weighted avg       0.79      0.77      0.77     16984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Construction de X (DataFrame d'entrée pour la pipeline) et y\n",
    "X = df[[\"designation_cleaned\", \"description_cleaned\"] + meta_cols]\n",
    "y = df[\"prdtypecode\"].values\n",
    "\n",
    "# Split entraînement / validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(\"Taille X_train :\", X_train.shape)\n",
    "print(\"Taille X_valid :\", X_valid.shape)\n",
    "\n",
    "# Entraînement de la pipeline complète\n",
    "print(\"Entraînement du modèle (pipeline complet)...\")\n",
    "clf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur le jeu de validation\n",
    "y_pred = clf_pipeline.predict(X_valid)\n",
    "\n",
    "# Évaluation\n",
    "weighted_f1 = f1_score(y_valid, y_pred, average=\"weighted\")\n",
    "print(f\"\\nWeighted F1 (validation) : {weighted_f1:.4f}\\n\")\n",
    "\n",
    "print(\"Classification report :\\n\")\n",
    "print(classification_report(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099e93b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de la GridSearch (peut être un peu long)...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=12.5min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.0min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.4min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.5min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.9min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.0min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.2min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.6min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.6min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.7min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=15.3min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=16.1min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=16.3min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=16.9min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=17.1min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=17.9min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=12.6min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.0min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.4min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.8min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.2min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=16.8min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.8min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=13.3min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=16.4min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=17.1min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.5min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=15.4min\n",
      "[CV] END model__C=0.5, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=17.5min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.3min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=14.2min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=16.0min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=15.7min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.0min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.4min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.2min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=13.5min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=16.8min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=17.3min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=10000; total time=14.0min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=13.7min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=18.0min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.2min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=17.6min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=16.2min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=16.6min\n",
      "[CV] END model__C=1.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=17.3min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=14.7min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time= 9.4min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time= 9.3min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time= 9.5min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=11.4min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=20000, preprocess__title_tfidf__max_features=20000; total time=11.6min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time= 9.5min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=11.4min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=10000; total time=10.9min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=10.6min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=10.6min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=11.1min\n",
      "[CV] END model__C=2.0, preprocess__desc_tfidf__max_features=30000, preprocess__title_tfidf__max_features=20000; total time=10.6min\n",
      "\n",
      "Meilleurs paramètres trouvés : {'model__C': 2.0, 'preprocess__desc_tfidf__max_features': 30000, 'preprocess__title_tfidf__max_features': 10000}\n",
      "Meilleur score (F1 pondéré, CV) : 0.7668128962329079\n",
      "\n",
      "Weighted F1 du meilleur modèle sur validation : 0.7731\n",
      "\n",
      "Classification report du meilleur modèle :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.34      0.72      0.46       623\n",
      "          40       0.78      0.60      0.67       502\n",
      "          50       0.77      0.79      0.78       336\n",
      "          60       0.86      0.77      0.81       166\n",
      "        1140       0.71      0.80      0.75       534\n",
      "        1160       0.83      0.90      0.86       791\n",
      "        1180       0.51      0.59      0.55       153\n",
      "        1280       0.75      0.48      0.59       974\n",
      "        1281       0.57      0.56      0.57       414\n",
      "        1300       0.83      0.86      0.84      1009\n",
      "        1301       0.90      0.93      0.91       161\n",
      "        1302       0.78      0.73      0.75       498\n",
      "        1320       0.75      0.66      0.70       648\n",
      "        1560       0.83      0.76      0.80      1015\n",
      "        1920       0.89      0.87      0.88       861\n",
      "        1940       0.67      0.93      0.78       161\n",
      "        2060       0.77      0.75      0.76       999\n",
      "        2220       0.75      0.83      0.79       165\n",
      "        2280       0.83      0.80      0.82       952\n",
      "        2403       0.69      0.69      0.69       955\n",
      "        2462       0.70      0.80      0.75       284\n",
      "        2522       0.91      0.84      0.87       998\n",
      "        2582       0.68      0.72      0.70       518\n",
      "        2583       0.98      0.89      0.93      2042\n",
      "        2585       0.73      0.77      0.75       499\n",
      "        2705       0.74      0.67      0.70       552\n",
      "        2905       0.98      0.99      0.98       174\n",
      "\n",
      "    accuracy                           0.77     16984\n",
      "   macro avg       0.76      0.77      0.76     16984\n",
      "weighted avg       0.79      0.77      0.77     16984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"model__C\": [0.5, 1.0, 2.0],\n",
    "    \"preprocess__title_tfidf__max_features\": [10000, 20000],\n",
    "    \"preprocess__desc_tfidf__max_features\": [20000, 30000],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1_weighted\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"Lancement de la GridSearch (peut être un peu long)...\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nMeilleurs paramètres trouvés :\", grid.best_params_)\n",
    "print(\"Meilleur score (F1 pondéré, CV) :\", grid.best_score_)\n",
    "\n",
    "# Évaluation du meilleur modèle sur le jeu de validation\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_valid)\n",
    "best_f1 = f1_score(y_valid, y_pred_best, average=\"weighted\")\n",
    "\n",
    "print(f\"\\nWeighted F1 du meilleur modèle sur validation : {best_f1:.4f}\\n\")\n",
    "print(\"Classification report du meilleur modèle :\\n\")\n",
    "print(classification_report(y_valid, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb60bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
