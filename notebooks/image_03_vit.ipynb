{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT Canonical Training + Phase 3 Export (Colab)\n",
    "\n",
    "**Model:** Vision Transformer (ViT-Tiny via timm)\n",
    "\n",
    "**Objective:** Replicate ResNet50 canonical pipeline with ViT:\n",
    "- Phase 1: Canonical splits (load from Drive)\n",
    "- Phase 2: Canonical classes (27 classes, fp=cdfa70b13f7390e6)\n",
    "- Phase 3: Export contract (.npz + _meta.json) with strict validation\n",
    "\n",
    "**Expected outputs:**\n",
    "- `STORE/artifacts/exports/vit_rerun_canonical_smoke/val.npz`\n",
    "- `STORE/artifacts/exports/vit_rerun_canonical_smoke/val_meta.json`\n",
    "\n",
    "**Validation:**\n",
    "- split_signature must match ResNet50: `cf53f8eb169b3531`\n",
    "- classes_fp must equal canonical: `cdfa70b13f7390e6`\n",
    "- idx order must align with ResNet50 for fusion compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# --- EDIT THESE PATHS ONCE ---\n",
    "DRIVE_CODE_SNAPSHOT = Path(\"/content/drive/MyDrive/DS_rakuten_colab\")\n",
    "DRIVE_STORE = Path(\"/content/drive/MyDrive/DS_rakuten_store\")\n",
    "DRIVE_SPLITS_SRC = DRIVE_STORE / \"splits\"   # expects train_idx.txt / val_idx.txt / test_idx.txt\n",
    "# ----------------------------\n",
    "\n",
    "assert DRIVE_CODE_SNAPSHOT.exists(), f\"Missing code snapshot: {DRIVE_CODE_SNAPSHOT}\"\n",
    "DRIVE_STORE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"DS_RAKUTEN_STORE\"] = str(DRIVE_STORE)\n",
    "\n",
    "print(\"✓ DRIVE_CODE_SNAPSHOT:\", DRIVE_CODE_SNAPSHOT)\n",
    "print(\"✓ DRIVE_STORE:\", DRIVE_STORE)\n",
    "print(\"✓ DRIVE_SPLITS_SRC:\", DRIVE_SPLITS_SRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "RUNTIME_ROOT = Path(\"/content/DS_rakuten\")\n",
    "\n",
    "# Clean and copy for deterministic imports\n",
    "if RUNTIME_ROOT.exists():\n",
    "    shutil.rmtree(RUNTIME_ROOT)\n",
    "\n",
    "shutil.copytree(DRIVE_CODE_SNAPSHOT, RUNTIME_ROOT)\n",
    "\n",
    "sys.path.insert(0, str(RUNTIME_ROOT))\n",
    "\n",
    "print(\"✓ Runtime code ready:\", RUNTIME_ROOT)\n",
    "print(\"✓ sys.path[0]:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "runtime_splits_dir = Path(\"/content/DS_rakuten/data/splits\")\n",
    "runtime_splits_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy txt files from Drive persistent store into /content runtime repo\n",
    "src_files = [\"train_idx.txt\", \"val_idx.txt\", \"test_idx.txt\"]\n",
    "for fn in src_files:\n",
    "    src = DRIVE_SPLITS_SRC / fn\n",
    "    dst = runtime_splits_dir / fn\n",
    "    assert src.exists(), f\"Missing split file in Drive: {src}\"\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "print(\"✓ Splits synced to:\", runtime_splits_dir)\n",
    "print(\"✓ Contents:\", list(runtime_splits_dir.glob(\"*.txt\"))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install timm for Vision Transformer models\n",
    "!pip -q install timm\n",
    "\n",
    "# Uncomment if your session is missing other packages:\n",
    "# !pip -q install gdown\n",
    "# !pip -q install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGE_FILE_ID = \"15ZkS0iTQ7j3mHpxil4mABlXwP-jAN_zi\"\n",
    "\n",
    "BASE_DIR = Path(\"/content/images\")\n",
    "TMP_DIR = Path(\"/content/tmp\")\n",
    "ZIP_PATH = TMP_DIR / \"images.zip\"\n",
    "\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not ZIP_PATH.exists():\n",
    "    print(\"Downloading images zip...\")\n",
    "    !gdown --id $IMAGE_FILE_ID -O {str(ZIP_PATH)}\n",
    "else:\n",
    "    print(\"Zip already present:\", ZIP_PATH)\n",
    "\n",
    "print(\"Unzipping images...\")\n",
    "!unzip -q -o {str(ZIP_PATH)} -d {str(BASE_DIR)}\n",
    "\n",
    "def count_jpgs(p: Path, limit: int = 2000) -> int:\n",
    "    if not p.exists():\n",
    "        return 0\n",
    "    n = 0\n",
    "    for _ in p.rglob(\"*.jpg\"):\n",
    "        n += 1\n",
    "        if n >= limit:\n",
    "            break\n",
    "    return n\n",
    "\n",
    "# Common candidates\n",
    "candidates = [\n",
    "    BASE_DIR / \"images\" / \"image_train\",\n",
    "    BASE_DIR / \"image_train\",\n",
    "    BASE_DIR / \"images\" / \"images\" / \"image_train\",\n",
    "]\n",
    "\n",
    "best = None\n",
    "best_count = 0\n",
    "for c in candidates:\n",
    "    n = count_jpgs(c)\n",
    "    if n > best_count:\n",
    "        best, best_count = c, n\n",
    "\n",
    "# Fallback: search any folder named image_train\n",
    "if best_count == 0:\n",
    "    for c in BASE_DIR.rglob(\"image_train\"):\n",
    "        if c.is_dir():\n",
    "            n = count_jpgs(c)\n",
    "            if n > best_count:\n",
    "                best, best_count = c, n\n",
    "\n",
    "assert best is not None and best_count > 0, (\n",
    "    \"Could not find an image_train directory with jpg files under /content/images. \"\n",
    "    \"Check zip content and unzip path.\"\n",
    ")\n",
    "\n",
    "IMG_ROOT = best\n",
    "sample_jpg = next(IMG_ROOT.rglob(\"*.jpg\"))\n",
    "\n",
    "print(\"✓ IMG_ROOT detected:\", IMG_ROOT)\n",
    "print(\"✓ sample jpg:\", sample_jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.image_dataset import RakutenImageDataset\n",
    "from src.train.image_vit import ViTConfig, run_vit_canonical\n",
    "\n",
    "print(\"✓ RakutenImageDataset:\", RakutenImageDataset)\n",
    "print(\"✓ ViTConfig:\", ViTConfig)\n",
    "print(\"✓ run_vit_canonical:\", run_vit_canonical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.split_manager import load_splits, split_signature\n",
    "\n",
    "splits = load_splits(verbose=True)\n",
    "sig = split_signature(splits)\n",
    "\n",
    "print(\"✓ signature:\", sig)\n",
    "print({k: len(v) for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\nSTORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\n\ncfg = ViTConfig(\n    raw_dir=str(STORE / \"data_raw\"),\n    img_dir=str(IMG_ROOT),  # must be /content local disk for speed\n    out_dir=str(STORE / \"artifacts\" / \"exports\"),\n    ckpt_dir=str(STORE / \"checkpoints\" / \"image_vit\"),\n\n    img_size=224,\n    batch_size=64,  # ViT: smaller batch for stability\n    num_workers=8,\n    num_epochs=1,   # Smoke test: 1 epoch\n    lr=1e-4,\n\n    use_amp=True,\n    label_smoothing=0.1,\n    dropout_rate=0.1,\n\n    vit_model_name=\"vit_tiny_patch16_224\",\n    vit_pretrained=True,\n\n    force_colab_loader=True,  # Force Colab data loader\n\n    model_name=\"vit_rerun_canonical_smoke\",\n    export_split=\"val\",\n)\n\nresult = run_vit_canonical(cfg)\n\nprint(\"EXPORT:\", result[\"export_result\"])\nprint(\"VERIFY:\", result[\"verify_metadata\"])\nprint(\"probs_shape:\", result[\"probs_shape\"])\nprint(\"best_val_f1:\", result[\"best_val_f1\"])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "STORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\n",
    "export_dir = STORE / \"artifacts\" / \"exports\" / \"vit_rerun_canonical_smoke\"\n",
    "\n",
    "print(\"Export dir:\", export_dir)\n",
    "print(\"Contents:\", [p.name for p in export_dir.glob(\"*\")])\n",
    "\n",
    "assert (export_dir / \"val.npz\").exists(), \"Missing val.npz\"\n",
    "assert (export_dir / \"val_meta.json\").exists(), \"Missing val_meta.json\"\n",
    "print(\"✓ Export files exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!python -m apps.image_app.scripts.validate_exports --split val --exports-root \"$DS_RAKUTEN_STORE/artifacts/exports\" --strict"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "STORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\n",
    "meta_path = STORE / \"artifacts\" / \"exports\" / \"vit_rerun_canonical_smoke\" / \"val_meta.json\"\n",
    "\n",
    "meta = json.loads(meta_path.read_text())\n",
    "keys = [\n",
    "    \"model_name\", \"split_name\", \"split_signature\",\n",
    "    \"classes_fp\", \"num_samples\", \"probs_shape\"\n",
    "]\n",
    "for k in keys:\n",
    "    print(f\"{k}: {meta.get(k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from src.export.model_exporter import load_predictions\n",
    "from src.data.label_mapping import CANONICAL_CLASSES_FP\n",
    "from src.data.split_manager import load_splits, split_signature\n",
    "\n",
    "splits = load_splits(verbose=False)\n",
    "sig = split_signature(splits)\n",
    "\n",
    "CACHE = Path(\"/content/cache_exports\")\n",
    "CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "export_result = result[\"export_result\"]\n",
    "npz_src = Path(export_result[\"npz_path\"])\n",
    "meta_src = npz_src.with_name(npz_src.stem + \"_meta.json\")\n",
    "\n",
    "npz_local = CACHE / npz_src.name\n",
    "meta_local = CACHE / meta_src.name\n",
    "\n",
    "# Copy both files (npz + meta)\n",
    "if (not npz_local.exists()) or (npz_local.stat().st_size != npz_src.stat().st_size):\n",
    "    shutil.copy2(npz_src, npz_local)\n",
    "\n",
    "if (not meta_local.exists()) or (meta_local.stat().st_size != meta_src.stat().st_size):\n",
    "    shutil.copy2(meta_src, meta_local)\n",
    "\n",
    "loaded = load_predictions(\n",
    "    npz_path=str(npz_local),\n",
    "    verify_split_signature=sig,\n",
    "    verify_classes_fp=CANONICAL_CLASSES_FP,\n",
    "    require_y_true=True,\n",
    ")\n",
    "\n",
    "print(\"✓ loaded ok\")\n",
    "print(\"model:\", loaded[\"metadata\"][\"model_name\"])\n",
    "print(\"split:\", loaded[\"metadata\"][\"split_name\"])\n",
    "print(\"sig:\", loaded[\"metadata\"][\"split_signature\"])\n",
    "print(\"fp:\", loaded[\"metadata\"][\"classes_fp\"])\n",
    "print(\"probs:\", loaded[\"probs\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "STORE = Path(os.environ[\"DS_RAKUTEN_STORE\"])\n",
    "export_dir = STORE / \"artifacts\" / \"exports\" / \"vit_rerun_canonical_smoke\"\n",
    "\n",
    "print(\"Export dir:\", export_dir)\n",
    "print(\"Files:\", [p.name for p in export_dir.glob(\"*\")])\n",
    "\n",
    "assert (export_dir / \"val.npz\").exists(), \"Missing val.npz\"\n",
    "assert (export_dir / \"val_meta.json\").exists(), \"Missing val_meta.json\"\n",
    "print(\"✓ Export files exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}